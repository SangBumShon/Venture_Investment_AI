# app/services/external/rag_service.py (Host ì •ë³´ í¬í•¨ ë²„ì „)
import os
import hashlib
from pathlib import Path
from typing import List, Dict, Any, Optional
import uuid

from pinecone import Pinecone, ServerlessSpec
from langchain_openai import OpenAIEmbeddings
from langchain_community.document_loaders import PyMuPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.retrievers import BM25Retriever
from langchain_core.documents import Document
from sentence_transformers import CrossEncoder

class RAGService:
    """RAG ê²€ìƒ‰ ì„œë¹„ìŠ¤ (Pinecone + Ensemble Retriever + CrossEncoder Reranker)"""
    
    def __init__(self):
        self.embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
        self.reranker = self._init_crossencoder()
        self.pc = None
        self.index = None
        self.doc_texts = []
        self.all_docs = []
        self._init_pinecone()
    
    def _init_crossencoder(self):
        """CrossEncoder Reranker ì´ˆê¸°í™”"""
        try:
            # í•œêµ­ì–´ë„ ì˜ ì²˜ë¦¬í•˜ëŠ” ë‹¤êµ­ì–´ ëª¨ë¸ ì‚¬ìš©
            model_name = "cross-encoder/ms-marco-MiniLM-L-6-v2"
            reranker = CrossEncoder(model_name)
            print(f"[INFO] CrossEncoder Reranker ë¡œë“œ ì™„ë£Œ: {model_name}")
            return reranker
        except Exception as e:
            print(f"[ERROR] CrossEncoder ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return None
    
    def _init_pinecone(self):
        """Pinecone ì´ˆê¸°í™” (Host ì •ë³´ í¬í•¨)"""
        api_key = os.getenv("PINECONE_API_KEY")
        if not api_key:
            print("[WARNING] PINECONE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        try:
            # Pinecone í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            self.pc = Pinecone(api_key=api_key)
            
            index_name = os.getenv("PINECONE_INDEX_NAME", "startup-analysis")
            
            # ê¸°ì¡´ ì¸ë±ìŠ¤ ëª©ë¡ì—ì„œ í™•ì¸
            existing_indexes = [idx.name for idx in self.pc.list_indexes()]
            
            if index_name not in existing_indexes:
                print(f"[INFO] Pinecone ì¸ë±ìŠ¤ '{index_name}' ìƒì„± ì¤‘...")
                
                # ServerlessSpecìœ¼ë¡œ ìƒì„±
                self.pc.create_index(
                    name=index_name,
                    dimension=1536,  # text-embedding-3-small dimension
                    metric="cosine",
                    spec=ServerlessSpec(
                        cloud="aws",
                        region=os.getenv("PINECONE_ENVIRONMENT", "us-east-1")
                    )
                )
                print(f"[INFO] Pinecone ì¸ë±ìŠ¤ '{index_name}' ìƒì„± ì™„ë£Œ")
            
            # Host URLë¡œ ì§ì ‘ ì—°ê²° ì‹œë„ (ì„¤ì •ëœ ê²½ìš°)
            pinecone_host = os.getenv("PINECONE_HOST")
            if pinecone_host:
                # Hostê°€ ì„¤ì •ëœ ê²½ìš° ì§ì ‘ ì—°ê²°
                self.index = self.pc.Index(index_name, host=pinecone_host)
                print(f"[INFO] Pinecone ì¸ë±ìŠ¤ '{index_name}' Host ì—°ê²°: {pinecone_host}")
            else:
                # Hostê°€ ì—†ëŠ” ê²½ìš° ì¼ë°˜ ì—°ê²°
                self.index = self.pc.Index(index_name)
                print(f"[INFO] Pinecone ì¸ë±ìŠ¤ '{index_name}' ì¼ë°˜ ì—°ê²° ì™„ë£Œ")
            
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            try:
                stats = self.index.describe_index_stats()
                print(f"[INFO] ì¸ë±ìŠ¤ ìƒíƒœ: {stats.total_vector_count}ê°œ ë²¡í„° ì €ì¥ë¨")
            except Exception as e:
                print(f"[WARNING] ì¸ë±ìŠ¤ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
                # ìƒíƒœ í™•ì¸ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
            
        except Exception as e:
            print(f"[ERROR] Pinecone ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.pc = None
            self.index = None
            
            # ìƒì„¸ ì˜¤ë¥˜ ì •ë³´ ì¶œë ¥
            print("\nğŸ’¡ Pinecone ì„¤ì • í™•ì¸ ì‚¬í•­:")
            print("1. PINECONE_API_KEYê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸")
            print("2. PINECONE_INDEX_NAMEì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸")
            print("3. PINECONE_ENVIRONMENTê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸")
            print("4. í•„ìš”ì‹œ PINECONE_HOSTë¥¼ ì„¤ì •")
    
    def _generate_doc_id(self, doc_content: str, metadata: dict) -> str:
        """ë¬¸ì„œ ID ìƒì„±"""
        content_hash = hashlib.md5(doc_content.encode()).hexdigest()[:8]
        source = metadata.get('source', 'unknown')
        page = metadata.get('page', 0)
        return f"{Path(source).stem}_page{page}_{content_hash}"
    
    def load_and_index_documents(self, pdf_dir: Path) -> List[str]:
        """PDF ë¬¸ì„œ ë¡œë“œ ë° ì¸ë±ì‹±"""
        if not pdf_dir.exists():
            print(f"[WARNING] PDF ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {pdf_dir}")
            return []
        
        pdf_files = list(pdf_dir.glob("*.pdf"))
        if not pdf_files:
            print(f"[WARNING] PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {pdf_dir}")
            return []
        
        all_docs = []
        doc_texts = []
        
        print(f"[DEBUG] PDF íŒŒì¼ {len(pdf_files)}ê°œ ì²˜ë¦¬ ì‹œì‘...")
        print(f"[DEBUG] PDF íŒŒì¼ ëª©ë¡: {[f.name for f in pdf_files]}")
        
        for pdf_file in pdf_files:
            try:
                print(f"[DEBUG] '{pdf_file.name}' ì²˜ë¦¬ ì¤‘...")
                loader = PyMuPDFLoader(str(pdf_file))
                text_splitter = RecursiveCharacterTextSplitter(
                    chunk_size=1000, 
                    chunk_overlap=100
                )
                docs = loader.load_and_split(text_splitter)
                
                print(f"[DEBUG] '{pdf_file.name}' â†’ {len(docs)} ì²­í¬ ìƒì„±")
                if docs:
                    print(f"[DEBUG] ì²« ë²ˆì§¸ ì²­í¬ ìƒ˜í”Œ: {docs[0].page_content[:100]}...")
                
                # ë©”íƒ€ë°ì´í„° ë³´ê°•
                for doc in docs:
                    doc.metadata['source'] = str(pdf_file)
                    doc.metadata['filename'] = pdf_file.name
                
                all_docs.extend(docs)
                doc_texts.extend([doc.page_content for doc in docs])
                
            except Exception as e:
                print(f"[ERROR] PDF ë¡œë“œ ì‹¤íŒ¨ '{pdf_file.name}': {e}")
                import traceback
                traceback.print_exc()
        
        # ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ì— ì €ì¥
        self.all_docs = all_docs
        self.doc_texts = doc_texts
        
        print(f"[DEBUG] ì´ {len(all_docs)}ê°œ ë¬¸ì„œ ì²­í¬ ì²˜ë¦¬ ì™„ë£Œ")
        print(f"[DEBUG] Pinecone ì¸ë±ìŠ¤ ìƒíƒœ: {self.index is not None}")
        print(f"[DEBUG] ì„ë² ë”© ëª¨ë¸ ìƒíƒœ: {self.embeddings is not None}")
        
        # Pineconeì— ì—…ë¡œë“œ
        if self.index and all_docs:
            print(f"[DEBUG] Pinecone ì—…ë¡œë“œ ì‹œì‘...")
            self._upload_to_pinecone(all_docs)
        else:
            print(f"[DEBUG] Pinecone ì—…ë¡œë“œ ê±´ë„ˆëœ€ - index: {self.index is not None}, docs: {len(all_docs)}")
        
        return doc_texts
    
    def _upload_to_pinecone(self, docs: List[Document], batch_size: int = 100):
        """Pineconeì— ë¬¸ì„œ ì—…ë¡œë“œ"""
        print(f"[INFO] Pineconeì— {len(docs)}ê°œ ë¬¸ì„œ ì—…ë¡œë“œ ì‹œì‘...")
        
        try:
            vectors_to_upload = []
            successful_embeddings = 0
            failed_embeddings = 0
            
            print(f"[DEBUG] ì„ë² ë”© ëª¨ë¸ ì •ë³´: {type(self.embeddings)}")
            
            for i, doc in enumerate(docs):
                print(f"[DEBUG] ë¬¸ì„œ {i+1}/{len(docs)} ì²˜ë¦¬ ì¤‘...")
                print(f"[DEBUG] ë¬¸ì„œ ë‚´ìš© ê¸¸ì´: {len(doc.page_content)} ë¬¸ì")
                print(f"[DEBUG] ë¬¸ì„œ ë‚´ìš© ìƒ˜í”Œ: {doc.page_content[:100]}...")
                
                doc_id = self._generate_doc_id(doc.page_content, doc.metadata)
                
                # ì„ë² ë”© ìƒì„±
                try:
                    print(f"[DEBUG] ì„ë² ë”© ìƒì„± ì‹œë„...")
                    embedding = self.embeddings.embed_query(doc.page_content)
                    print(f"[DEBUG] ì„ë² ë”© ìƒì„± ì„±ê³µ - ì°¨ì›: {len(embedding)}")
                    print(f"[DEBUG] ì„ë² ë”© ìƒ˜í”Œ: {embedding[:5]}...")
                    
                    vector_data = {
                        "id": doc_id,
                        "values": embedding,
                        "metadata": {
                            "text": doc.page_content,
                            "source": doc.metadata.get('source', ''),
                            "page": doc.metadata.get('page', 0),
                            "filename": doc.metadata.get('filename', '')
                        }
                    }
                    vectors_to_upload.append(vector_data)
                    successful_embeddings += 1
                    
                except Exception as e:
                    print(f"[ERROR] ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
                    import traceback
                    traceback.print_exc()
                    failed_embeddings += 1
                    continue
                
                # ë°°ì¹˜ ì—…ë¡œë“œ
                if len(vectors_to_upload) >= batch_size:
                    print(f"[DEBUG] ë°°ì¹˜ ì—…ë¡œë“œ ì‹¤í–‰ ({len(vectors_to_upload)}ê°œ)...")
                    self._batch_upload(vectors_to_upload)
                    vectors_to_upload = []
            
            # ë‚¨ì€ ë²¡í„° ì—…ë¡œë“œ
            if vectors_to_upload:
                print(f"[DEBUG] ë§ˆì§€ë§‰ ë°°ì¹˜ ì—…ë¡œë“œ ì‹¤í–‰ ({len(vectors_to_upload)}ê°œ)...")
                self._batch_upload(vectors_to_upload)
            
            print(f"[INFO] Pinecone ì—…ë¡œë“œ ì™„ë£Œ - ì„±ê³µ: {successful_embeddings}, ì‹¤íŒ¨: {failed_embeddings}")
            
        except Exception as e:
            print(f"[ERROR] Pinecone ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
    
    def _batch_upload(self, vectors: List[Dict]):
        """ë°°ì¹˜ ë‹¨ìœ„ë¡œ Pineconeì— ì—…ë¡œë“œ"""
        try:
            self.index.upsert(vectors=vectors)
            print(f"[DEBUG] {len(vectors)}ê°œ ë²¡í„° ì—…ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"[ERROR] ë°°ì¹˜ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def _search_pinecone(self, query: str, k: int = 10) -> List[Document]:
        """Pineconeì—ì„œ ìœ ì‚¬ë„ ê²€ìƒ‰"""
        if not self.index:
            return []
        
        try:
            # ì¿¼ë¦¬ ì„ë² ë”©
            query_embedding = self.embeddings.embed_query(query)
            
            # Pinecone ê²€ìƒ‰
            results = self.index.query(
                vector=query_embedding,
                top_k=k,
                include_metadata=True
            )
            
            # Document ê°ì²´ë¡œ ë³€í™˜
            docs = []
            for match in results.matches:
                if match.metadata and 'text' in match.metadata:
                    doc = Document(
                        page_content=match.metadata['text'],
                        metadata={
                            'source': match.metadata.get('source', ''),
                            'page': match.metadata.get('page', 0),
                            'filename': match.metadata.get('filename', ''),
                            'score': match.score
                        }
                    )
                    docs.append(doc)
            
            print(f"[DEBUG] Pineconeì—ì„œ {len(docs)}ê°œ ë¬¸ì„œ ê²€ìƒ‰ë¨")
            return docs
            
        except Exception as e:
            print(f"[ERROR] Pinecone ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _crossencoder_rerank(self, query: str, documents: List[str], top_k: int = 4) -> List[str]:
        """CrossEncoderë¡œ ë¬¸ì„œ ì¬ìˆœìœ„í™”"""
        if not self.reranker or not documents:
            return documents[:top_k]
        
        try:
            # ì¿¼ë¦¬-ë¬¸ì„œ ìŒ ìƒì„±
            query_doc_pairs = [[query, doc] for doc in documents]
            
            # CrossEncoderë¡œ ì ìˆ˜ ê³„ì‚°
            scores = self.reranker.predict(query_doc_pairs)
            
            # ì ìˆ˜ì™€ ë¬¸ì„œë¥¼ í•¨ê»˜ ì •ë ¬
            scored_docs = list(zip(documents, scores))
            scored_docs.sort(key=lambda x: x[1], reverse=True)
            
            # ìƒìœ„ kê°œ ë¬¸ì„œ ë°˜í™˜
            reranked_docs = [doc for doc, score in scored_docs[:top_k]]
            
            print(f"[DEBUG] CrossEncoder ì¬ìˆœìœ„í™”: {len(documents)}ê°œ â†’ {len(reranked_docs)}ê°œ")
            return reranked_docs
            
        except Exception as e:
            print(f"[ERROR] CrossEncoder ì¬ìˆœìœ„í™” ì‹¤íŒ¨: {e}")
            return documents[:top_k]
    
    def create_ensemble_retriever(self, query: str, k: int = 4) -> List[str]:
        """Ensemble Retriever (Dense + Sparse + CrossEncoder Reranker)"""
        sparse_results = []
        dense_results = []
        
        # 1. BM25 (Sparse) Retriever
        if self.doc_texts:
            try:
                bm25_retriever = BM25Retriever.from_texts(self.doc_texts)
                bm25_retriever.k = k * 3  # ë” ë§ì´ ê°€ì ¸ì™€ì„œ ë‹¤ì–‘ì„± í™•ë³´
                sparse_results = bm25_retriever.get_relevant_documents(query)
                print(f"[DEBUG] BM25ì—ì„œ {len(sparse_results)}ê°œ ë¬¸ì„œ ê²€ìƒ‰ë¨")
            except Exception as e:
                print(f"[ERROR] BM25 ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        
        # 2. Dense Retriever (Pinecone)
        dense_results = self._search_pinecone(query, k * 3)
        
        # 3. ê²°ê³¼ í•©ì¹˜ê¸° ë° ì¤‘ë³µ ì œê±°
        all_results = []
        seen_contents = set()
        
        # Sparse ê²°ê³¼ ì¶”ê°€
        for doc in sparse_results:
            content_hash = hashlib.md5(doc.page_content.encode()).hexdigest()
            if content_hash not in seen_contents:
                seen_contents.add(content_hash)
                all_results.append(doc)
        
        # Dense ê²°ê³¼ ì¶”ê°€
        for doc in dense_results:
            content_hash = hashlib.md5(doc.page_content.encode()).hexdigest()
            if content_hash not in seen_contents:
                seen_contents.add(content_hash)
                all_results.append(doc)
        
        print(f"[DEBUG] Ensemble ê²°ê³¼: ì´ {len(all_results)}ê°œ ë¬¸ì„œ")
        
        # 4. CrossEncoder Reranker ì ìš©
        if all_results:
            documents = [doc.page_content for doc in all_results]
            reranked_docs = self._crossencoder_rerank(query, documents, top_k=k)
            return reranked_docs
        
        return []
    
    def get_index_stats(self) -> Dict[str, Any]:
        """Pinecone ì¸ë±ìŠ¤ í†µê³„ ì¡°íšŒ"""
        if not self.index:
            return {"error": "Pinecone ì¸ë±ìŠ¤ê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
        
        try:
            stats = self.index.describe_index_stats()
            return {
                "total_vector_count": stats.total_vector_count,
                "dimension": stats.dimension,
                "index_fullness": stats.index_fullness,
                "namespaces": dict(stats.namespaces) if stats.namespaces else {}
            }
        except Exception as e:
            return {"error": f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}"}
    
    def clear_index(self):
        """Pinecone ì¸ë±ìŠ¤ ì´ˆê¸°í™” (ê°œë°œìš©)"""
        if not self.index:
            print("[WARNING] Pinecone ì¸ë±ìŠ¤ê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        try:
            self.index.delete(delete_all=True)
            print("[INFO] Pinecone ì¸ë±ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"[ERROR] ì¸ë±ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    def check_pinecone_config(self):
        """Pinecone ì„¤ì • ìƒíƒœ ì²´í¬"""
        required_vars = ["PINECONE_API_KEY", "PINECONE_INDEX_NAME"]
        optional_vars = ["PINECONE_ENVIRONMENT", "PINECONE_HOST"]
        
        print("\nğŸ” Pinecone ì„¤ì • í™•ì¸:")
        
        # í•„ìˆ˜ ë³€ìˆ˜ ì²´í¬
        missing_required = []
        for var in required_vars:
            value = os.getenv(var)
            if value:
                print(f"âœ… {var}: ì„¤ì •ë¨")
            else:
                print(f"âŒ {var}: ëˆ„ë½")
                missing_required.append(var)
        
        # ì„ íƒì  ë³€ìˆ˜ ì²´í¬
        for var in optional_vars:
            value = os.getenv(var)
            if value:
                print(f"âœ… {var}: {value}")
            else:
                print(f"âš ï¸  {var}: ì„¤ì •ë˜ì§€ ì•ŠìŒ (ê¸°ë³¸ê°’ ì‚¬ìš©)")
        
        if missing_required:
            print(f"\nâŒ í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ ëˆ„ë½: {', '.join(missing_required)}")
            return False
        
        return True