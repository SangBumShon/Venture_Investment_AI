{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oosxbXULB9UP",
        "outputId": "c3a9f85f-4bde-491b-f01b-d74961fb7fab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement langchain_chromadb (from versions: none)\n",
            "ERROR: No matching distribution found for langchain_chromadb\n",
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# !pip install langchain_openai\n",
        "# !pip install langgraph --upgrade\n",
        "# !pip install dotenv\n",
        "# !pip install reportlab\n",
        "# !pip install langchain_teddynote\n",
        "# !pip install langchain_tavily\n",
        "# !pip install langchain_community\n",
        "# !pip install markdown2 weasyprint\n",
        "# !pip install pdfkit\n",
        "!pip install langchain_chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LangSmith 추적을 시작합니다.\n",
            "[프로젝트명]\n",
            "AI-project\n"
          ]
        }
      ],
      "source": [
        "from langchain_teddynote import logging\n",
        "\n",
        "logging.langsmith(\"AI-project\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import TypedDict, Literal\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle\n",
        "from reportlab.lib import colors\n",
        "import datetime\n",
        "import os\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. 상태 스키마 정의 (모든 Agent가 공유)\n",
        "class AgentState(TypedDict, total=False):\n",
        "    startup_name: str  # 스타트업 이름 추가\n",
        "    상품_점수: int\n",
        "    기술_점수: int\n",
        "    성장률_점수: int\n",
        "    시장성_점수: int\n",
        "    경쟁사_점수: int\n",
        "    최종_판단: Literal[\"투자\", \"보류\"]\n",
        "    보고서: str\n",
        "    pdf_path: str  # PDF 파일 경로 추가\n",
        "    # 분석 근거 추가\n",
        "    상품_분석_근거: str\n",
        "    기술_분석_근거: str\n",
        "    성장률_분석_근거: str\n",
        "    시장성_분석_근거: str\n",
        "    경쟁사_분석_근거: str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. LLM 초기화\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "File path 후보1.pdf is not a valid file or url",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[78], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# 1. PDF 로드\u001b[39;00m\n\u001b[0;32m      9\u001b[0m pdf_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m후보1.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 10\u001b[0m loader \u001b[38;5;241m=\u001b[39m \u001b[43mPyPDFLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m pages \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# 2. 텍스트 분할\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\lgw97\\Desktop\\skala_ai_startup_investment_evaluation_agent\\venv\\lib\\site-packages\\langchain_community\\document_loaders\\pdf.py:281\u001b[0m, in \u001b[0;36mPyPDFLoader.__init__\u001b[1;34m(self, file_path, password, headers, extract_images, mode, images_parser, images_inner_format, pages_delimiter, extraction_mode, extraction_kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    240\u001b[0m     file_path: Union[\u001b[38;5;28mstr\u001b[39m, PurePath],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    250\u001b[0m     extraction_kwargs: Optional[\u001b[38;5;28mdict\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    251\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    252\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Initialize with a file path.\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \n\u001b[0;32m    254\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;124;03m        `aload` methods to retrieve parsed documents with content and metadata.\u001b[39;00m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 281\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser \u001b[38;5;241m=\u001b[39m PyPDFParser(\n\u001b[0;32m    283\u001b[0m         password\u001b[38;5;241m=\u001b[39mpassword,\n\u001b[0;32m    284\u001b[0m         mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    290\u001b[0m         extraction_kwargs\u001b[38;5;241m=\u001b[39mextraction_kwargs,\n\u001b[0;32m    291\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\lgw97\\Desktop\\skala_ai_startup_investment_evaluation_agent\\venv\\lib\\site-packages\\langchain_community\\document_loaders\\pdf.py:140\u001b[0m, in \u001b[0;36mBasePDFLoader.__init__\u001b[1;34m(self, file_path, headers)\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(temp_pdf)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path):\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile path \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not a valid file or url\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path)\n",
            "\u001b[1;31mValueError\u001b[0m: File path 후보1.pdf is not a valid file or url"
          ]
        }
      ],
      "source": [
        "# 크로마 DB에 PDF 추가\n",
        "\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "# 1. PDF 로드\n",
        "pdf_path = \"후보1.pdf\"\n",
        "loader = PyPDFLoader(pdf_path)\n",
        "pages = loader.load()\n",
        "\n",
        "# 2. 텍스트 분할\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "docs = splitter.split_documents(pages)\n",
        "\n",
        "# 3. 임베딩 모델 설정\n",
        "embedding = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "# 4. Chroma에 저장\n",
        "db = Chroma.from_documents(documents=docs, embedding=embedding, persist_directory=\"chroma_db\")\n",
        "db.persist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import re\n",
        "from typing import List\n",
        "\n",
        "def analyze_product(state: AgentState) -> AgentState:\n",
        "    startup_name = state.get(\"startup_name\", \"\")\n",
        "    if not startup_name:\n",
        "        state[\"상품_점수\"] = 0\n",
        "        state[\"상품_분석_근거\"] = \"스타트업 이름이 제공되지 않았습니다.\"\n",
        "        return state\n",
        "\n",
        "    # Env에서 API 키 로드\n",
        "    travily_key = os.getenv(\"TAVILY_API_KEY\")\n",
        "    naver_id = os.getenv(\"NAVER_CLIENT_ID\")\n",
        "    naver_secret = os.getenv(\"NAVER_CLIENT_SECRET\")\n",
        "    if not travily_key or not naver_id or not naver_secret:\n",
        "        state[\"상품_점수\"] = 0\n",
        "        state[\"상품_분석_근거\"] = \"API 키가 설정되지 않았습니다. .env 파일을 확인해주세요.\"\n",
        "        return state\n",
        "\n",
        "    checklist = [\n",
        "        \"제품이 명확한 문제를 해결하는가?\",\n",
        "        \"제품 기능이 사용자가 기대하는 가치를 제공하는가?\",\n",
        "        \"제품의 차별화 요소가 명확한가?\",\n",
        "        \"제품의 사용성(UI/UX)이 직관적인가?\",\n",
        "        \"제품의 기술적 구현 가능성이 높은가?\",\n",
        "        \"제품의 시장 수요가 충분한가?\",\n",
        "        \"제품 가격 전략이 합리적인가?\",\n",
        "        \"제품 출시 및 확장 계획이 구체적인가?\",\n",
        "        \"경쟁 제품 대비 우위가 있는가?\",\n",
        "        \"고객 피드백 수집 및 반영 체계가 갖춰져 있는가?\"\n",
        "    ]\n",
        "    items_formatted = \"\\n\".join(f\"{i+1}. {q}\" for i, q in enumerate(checklist))\n",
        "\n",
        "    # Travily API\n",
        "    travily_url = \"https://api.tavily.com/v1/search\"\n",
        "    travily_params = {\"query\": startup_name, \"limit\": 5}\n",
        "    travily_headers = {\"Authorization\": f\"Bearer {travily_key}\"}\n",
        "    travily_res = requests.get(travily_url, params=travily_params, headers=travily_headers)\n",
        "    travily_items = travily_res.json().get(\"items\", [])\n",
        "    travily_context = \"\\n\".join(f\"{i+1}. {it.get('title', '제목없음')} ({it.get('url')})\" for i, it in enumerate(travily_items)) or \"정보 없음\"\n",
        "\n",
        "    # Naver News API\n",
        "    naver_url = \"https://openapi.naver.com/v1/search/news.json\"\n",
        "    naver_headers = {\"X-Naver-Client-Id\": naver_id, \"X-Naver-Client-Secret\": naver_secret}\n",
        "    naver_params = {\"query\": startup_name, \"display\": 5}\n",
        "    naver_res = requests.get(naver_url, params=naver_params, headers=naver_headers)\n",
        "    naver_items = naver_res.json().get(\"items\", [])\n",
        "    naver_context = \"\\n\".join(f\"{i+1}. {it.get('title', '제목없음')} – {it.get('description', '')} ({it.get('originallink')})\" for i, it in enumerate(naver_items)) or \"정보 없음\"\n",
        "\n",
        "    # LLM Prompt\n",
        "    prompt_template = (\n",
        "        \"당신은 스타트업 '{startup_name}'의 제품/서비스를 다음 체크리스트 10문항에 따라 평가해야 합니다.\\n\\n\"\n",
        "        \"체크리스트:\\n{items}\\n\\n\"\n",
        "        \"다음 Travily API 결과(최대 5개)를 참고하세요:\\n{travily_context}\\n\"\n",
        "        \"다음 Naver News API 결과(최대 5개)를 참고하세요:\\n{naver_context}\\n\\n\"\n",
        "        \"평가 시 유의사항:\\n\"\n",
        "        \"- 정보가 부족하거나 명확하지 않을 경우 '정보 부족으로 점수 유보' 대신 관용적으로 5점 내외를 부여할 수 있습니다.\\n\"\n",
        "        \"- 부정적 근거가 명확하지 않다면 초기 스타트업 상황을 고려하여 가능성에 가중치를 두고 평가하세요.\\n\\n\"\n",
        "        \"점수 부여 기준:\\n\"\n",
        "        \"- 매우 우수하거나 충분히 충족 → 9~10점\\n\"\n",
        "        \"- 일부 충족되었거나 불완전 → 5~8점\\n\"\n",
        "        \"- 거의 정보가 없거나 충족되지 않음 → 0~4점\\n\\n\"\n",
        "        \"각 문항별 점수(0~10)와 판단 근거를 작성하세요.\\n\"\n",
        "        \"판단 근거 뒤에는 관련 URL을 괄호 안에 포함하세요. URL이 없을 경우 '정보 없음'으로 표기하세요.\\n\"\n",
        "        \"마지막에 총점: 숫자 (숫자만 입력, 예: 75)를 작성하세요.\"\n",
        "    )\n",
        "    prompt = ChatPromptTemplate.from_template(prompt_template)\n",
        "    response = (prompt | llm).invoke({\n",
        "        \"startup_name\": startup_name,\n",
        "        \"items\": items_formatted,\n",
        "        \"travily_context\": travily_context,\n",
        "        \"naver_context\": naver_context\n",
        "    })\n",
        "\n",
        "    # 결과 파싱\n",
        "    analysis = response.content\n",
        "    score = extract_total_score_from_analysis(analysis)\n",
        "    if score is None:\n",
        "        score = extract_checklist_scores(analysis, checklist)\n",
        "\n",
        "    state[\"상품_점수\"] = score\n",
        "    state[\"상품_분석_근거\"] = analysis\n",
        "    return state\n",
        "\n",
        "# ✔ 공통 점수 파싱 유틸 함수\n",
        "def extract_total_score_from_analysis(analysis: str) -> int:\n",
        "    patterns = [\n",
        "        r\"\\*\\*총점\\*\\*[:：]?\\s*(\\d{1,3})\",\n",
        "        r\"총점[:：]?\\s*(\\d{1,3})\\s*(?:점|/100)?\",\n",
        "        r\"Score[:：]?\\s*(\\d{1,3})\\s*(?:점|/100)?\",\n",
        "    ]\n",
        "    for pattern in patterns:\n",
        "        match = re.search(pattern, analysis, re.IGNORECASE)\n",
        "        if match:\n",
        "            return int(match.group(1))\n",
        "    return None\n",
        "\n",
        "def extract_checklist_scores(analysis: str, checklist: List[str]) -> int:\n",
        "    clean_analysis = re.sub(r\"총점[:：]?\\s*\\d{1,3}\\s*(?:점|/100)?\", \"\", analysis, flags=re.IGNORECASE)\n",
        "    total_score = 0\n",
        "    for i, item in enumerate(checklist, 1):\n",
        "        patterns = [\n",
        "            fr\"{i}\\.\\s.*?(\\d{{1,2}})\\s*/\\s*10\",\n",
        "            fr\"{i}\\.\\s.*?(\\d{{1,2}})점\",\n",
        "            fr\"{i}\\.\\s.*?점수[:：]?\\s*(\\d{{1,2}})\",\n",
        "            fr\"{item}.*?(\\d{{1,2}})\\s*/\\s*10\",\n",
        "            fr\"{item}.*?(\\d{{1,2}})점\",\n",
        "            fr\"{item}.*?점수[:：]?\\s*(\\d{{1,2}})\",\n",
        "        ]\n",
        "        found = False\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, clean_analysis, re.DOTALL | re.IGNORECASE)\n",
        "            if match:\n",
        "                item_score = int(match.group(1))\n",
        "                total_score += item_score\n",
        "                found = True\n",
        "                break\n",
        "    return min(100, max(0, total_score))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, re, requests\n",
        "from typing import List\n",
        "\n",
        "# 정보 부족 항목 추출 (옵션)\n",
        "def extract_insufficient_items(text: str, checklist: List[str]) -> List[str]:\n",
        "    return [\n",
        "        item for item in checklist\n",
        "        if re.search(fr\"{re.escape(item)}.*?0점\", text) or \"정보 없음\" in text or \"근거 부족\" in text\n",
        "    ]\n",
        "\n",
        "# 메인 함수\n",
        "def analyze_technology(state: \"AgentState\") -> \"AgentState\":\n",
        "    startup_name = state.get(\"startup_name\", \"\")\n",
        "    if not startup_name:\n",
        "        state[\"기술_점수\"] = 0\n",
        "        state[\"기술_분석_근거\"] = \"스타트업 이름이 제공되지 않았습니다.\"\n",
        "        return state\n",
        "\n",
        "    travily_key = os.getenv(\"TAVILY_API_KEY\")\n",
        "    naver_id = os.getenv(\"NAVER_CLIENT_ID\")\n",
        "    naver_secret = os.getenv(\"NAVER_CLIENT_SECRET\")\n",
        "    if not travily_key or not naver_id or not naver_secret:\n",
        "        state[\"기술_점수\"] = 0\n",
        "        state[\"기술_분석_근거\"] = \"API 키가 설정되지 않았습니다. .env 파일을 확인해주세요.\"\n",
        "        return state\n",
        "\n",
        "    checklist = [\n",
        "        \"기술적 차별성\", \"특허 보유 여부\", \"스케일링 가능성\", \"기술 성숙도\",\n",
        "        \"인력 역량\", \"기술 난이도\", \"기술 구현 가능성\", \"기술 유지보수 용이성\",\n",
        "        \"기술 표준 준수 여부\", \"기술 관련 외부 인증 또는 수상 이력\"\n",
        "    ]\n",
        "    items_formatted = \"\\n\".join(f\"{i+1}. {q}\" for i, q in enumerate(checklist))\n",
        "\n",
        "    prompt_template = (\n",
        "        \"당신은 스타트업 '{startup_name}'의 기술력을 다음 체크리스트 10문항에 따라 평가해야 합니다.\\n\\n\"\n",
        "        \"체크리스트:\\n{items}\\n\\n\"\n",
        "        \"다음 Travily API 결과(최대 5개)를 참고하세요:\\n{travily_context}\\n\"\n",
        "        \"다음 Naver News API 결과(최대 5개)를 참고하세요:\\n{naver_context}\\n\\n\"\n",
        "        \"평가 시 유의사항:\\n\"\n",
        "        \"- 정보가 부족하거나 명확하지 않을 경우 '정보 부족으로 점수 유보' 대신 관용적으로 5점 내외를 부여할 수 있습니다.\\n\"\n",
        "        \"- 부정적 근거가 명확하지 않다면 초기 스타트업 상황을 고려하여 가능성에 가중치를 두고 평가하세요.\\n\\n\"\n",
        "        \"점수 부여 기준:\\n\"\n",
        "        \"- 매우 우수하거나 충분히 충족 → 9~10점\\n\"\n",
        "        \"- 일부 충족되었거나 불완전 → 5~8점\\n\"\n",
        "        \"- 거의 정보가 없거나 충족되지 않음 → 0~4점\\n\\n\"\n",
        "        \"각 문항별 점수(0~10)와 판단 근거를 작성하세요.\\n\"\n",
        "        \"판단 근거 뒤에는 관련 URL을 괄호 안에 포함하세요. URL이 없을 경우 '정보 없음'으로 표기하세요.\\n\"\n",
        "        \"마지막에 총점: 숫자 (숫자만 입력, 예: 75)를 작성하세요.\"\n",
        "    )\n",
        "    prompt = ChatPromptTemplate.from_template(prompt_template)\n",
        "\n",
        "    analysis = \"\"\n",
        "    for attempt in range(1, 4):\n",
        "        # Tavily\n",
        "        travily_url = \"https://api.tavily.com/v1/search\"\n",
        "        travily_params = {\"query\": startup_name, \"limit\": 5}\n",
        "        travily_headers = {\"Authorization\": f\"Bearer {travily_key}\"}\n",
        "        travily_res = requests.get(travily_url, params=travily_params, headers=travily_headers)\n",
        "        travily_items = travily_res.json().get(\"items\", [])\n",
        "        travily_context = \"\\n\".join([f\"{i+1}. {it.get('title', '제목없음')} ({it.get('url')})\" for i, it in enumerate(travily_items)]) or \"정보 없음\"\n",
        "\n",
        "        # Naver\n",
        "        naver_url = \"https://openapi.naver.com/v1/search/news.json\"\n",
        "        naver_headers = {\"X-Naver-Client-Id\": naver_id, \"X-Naver-Client-Secret\": naver_secret}\n",
        "        naver_params = {\"query\": startup_name, \"display\": 5}\n",
        "        naver_res = requests.get(naver_url, params=naver_params, headers=naver_headers)\n",
        "        naver_items = naver_res.json().get(\"items\", [])\n",
        "        naver_context = \"\\n\".join([f\"{i+1}. {it.get('title', '제목없음')} – {it.get('description', '')} ({it.get('originallink')})\" for i, it in enumerate(naver_items)]) or \"정보 없음\"\n",
        "\n",
        "        # LLM 호출\n",
        "        response = (prompt | llm).invoke({\n",
        "            \"startup_name\": startup_name,\n",
        "            \"items\": items_formatted,\n",
        "            \"travily_context\": travily_context,\n",
        "            \"naver_context\": naver_context\n",
        "        })\n",
        "        analysis = response.content\n",
        "\n",
        "        insufficient = extract_insufficient_items(analysis, checklist)\n",
        "        if len(insufficient) < 5 or attempt == 3:\n",
        "            break\n",
        "\n",
        "    # robust 점수 파싱\n",
        "    score = extract_total_score_from_analysis(analysis)\n",
        "    if score is None:\n",
        "        score = extract_checklist_scores(analysis, checklist)\n",
        "\n",
        "    state[\"기술_점수\"] = score\n",
        "    state[\"기술_분석_근거\"] = analysis\n",
        "    return state\n",
        "\n",
        "# 점수 파싱 유틸 함수 (공통 사용)\n",
        "def extract_total_score_from_analysis(analysis: str) -> int:\n",
        "    patterns = [\n",
        "        r\"\\*\\*총점\\*\\*[:：]?\\s*(\\d{1,3})\",\n",
        "        r\"총점[:：]?\\s*(\\d{1,3})\\s*(?:점|/100)?\",\n",
        "        r\"Score[:：]?\\s*(\\d{1,3})\\s*(?:점|/100)?\",\n",
        "    ]\n",
        "    for pattern in patterns:\n",
        "        match = re.search(pattern, analysis, re.IGNORECASE)\n",
        "        if match:\n",
        "            return int(match.group(1))\n",
        "    return None\n",
        "\n",
        "def extract_checklist_scores(analysis: str, checklist: List[str]) -> int:\n",
        "    clean_analysis = re.sub(r\"총점[:：]?\\s*\\d{1,3}\\s*(?:점|/100)?\", \"\", analysis, flags=re.IGNORECASE)\n",
        "    total_score = 0\n",
        "    for i, item in enumerate(checklist, 1):\n",
        "        patterns = [\n",
        "            fr\"{i}\\.\\s.*?(\\d{{1,2}})\\s*/\\s*10\",\n",
        "            fr\"{i}\\.\\s.*?(\\d{{1,2}})점\",\n",
        "            fr\"{i}\\.\\s.*?점수[:：]?\\s*(\\d{{1,2}})\",\n",
        "            fr\"{item}.*?(\\d{{1,2}})\\s*/\\s*10\",\n",
        "            fr\"{item}.*?(\\d{{1,2}})점\",\n",
        "            fr\"{item}.*?점수[:：]?\\s*(\\d{{1,2}})\",\n",
        "        ]\n",
        "        found = False\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, clean_analysis, re.DOTALL | re.IGNORECASE)\n",
        "            if match:\n",
        "                item_score = int(match.group(1))\n",
        "                total_score += item_score\n",
        "                found = True\n",
        "                break\n",
        "    return min(100, max(0, total_score))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, re, requests\n",
        "from typing import List\n",
        "\n",
        "def analyze_growth(state: \"AgentState\") -> \"AgentState\":\n",
        "    startup_name = state.get(\"startup_name\", \"\")\n",
        "    if not startup_name:\n",
        "        state[\"성장률_점수\"] = 0\n",
        "        state[\"성장률_분석_근거\"] = \"스타트업 이름이 제공되지 않았습니다.\"\n",
        "        return state\n",
        "\n",
        "    travily_key = os.getenv(\"TAVILY_API_KEY\")\n",
        "    naver_id = os.getenv(\"NAVER_CLIENT_ID\")\n",
        "    naver_secret = os.getenv(\"NAVER_CLIENT_SECRET\")\n",
        "    if not travily_key or not naver_id or not naver_secret:\n",
        "        state[\"성장률_점수\"] = 0\n",
        "        state[\"성장률_분석_근거\"] = \"API 키가 설정되지 않았습니다. .env 파일을 확인해주세요.\"\n",
        "        return state\n",
        "\n",
        "    checklist = [\n",
        "        \"매출 성장률\", \"사용자 증가율\", \"시장 점유율 변화\", \"고객 유지율 (Retention Rate)\",\n",
        "        \"월간/분기별 활성 사용자 증가 (MAU/WAU)\", \"신규 계약/클라이언트 수 증가\", \"연간 반복 매출(ARR) 성장\",\n",
        "        \"투자 유치 규모 변화\", \"직원 수 증가율\", \"해외/신시장 진출 속도\"\n",
        "    ]\n",
        "    items_formatted = \"\\n\".join(f\"{i+1}. {q}\" for i, q in enumerate(checklist))\n",
        "\n",
        "    prompt_template = (\n",
        "        \"당신은 스타트업 '{startup_name}'의 성장률을 다음 체크리스트 10문항에 따라 평가해야 합니다.\\n\\n\"\n",
        "        \"체크리스트:\\n{items}\\n\\n\"\n",
        "        \"다음 Travily API 결과(최대 5개)를 참고하세요:\\n{travily_context}\\n\"\n",
        "        \"다음 Naver News API 결과(최대 5개)를 참고하세요:\\n{naver_context}\\n\\n\"\n",
        "        \"평가 시 유의사항:\\n\"\n",
        "        \"- 정보가 부족하거나 명확하지 않을 경우 '정보 부족으로 점수 유보' 대신 관용적으로 5점 내외를 부여할 수 있습니다.\\n\"\n",
        "        \"- 부정적 근거가 명확하지 않다면 초기 스타트업 상황을 고려하여 가능성에 가중치를 두고 평가하세요.\\n\\n\"\n",
        "        \"점수 부여 기준:\\n\"\n",
        "        \"- 매우 우수하거나 충분히 충족 → 9~10점\\n\"\n",
        "        \"- 일부 충족되었거나 불완전 → 5~8점\\n\"\n",
        "        \"- 거의 정보가 없거나 충족되지 않음 → 0~4점\\n\\n\"\n",
        "        \"각 문항별 점수(0~10)와 판단 근거를 작성하세요.\\n\"\n",
        "        \"판단 근거 뒤에는 관련 URL을 괄호 안에 포함하세요. URL이 없을 경우 '정보 없음'으로 표기하세요.\\n\"\n",
        "        \"마지막에 총점: 숫자 (숫자만 입력, 예: 75)를 작성하세요.\"\n",
        "    )\n",
        "    prompt = ChatPromptTemplate.from_template(prompt_template)\n",
        "\n",
        "    # LLM 호출 (재시도 제거, 1회 평가로 간소화 가능)\n",
        "    travily_url = \"https://api.tavily.com/v1/search\"\n",
        "    travily_params = {\"query\": startup_name, \"limit\": 5}\n",
        "    travily_headers = {\"Authorization\": f\"Bearer {travily_key}\"}\n",
        "    travily_res = requests.get(travily_url, params=travily_params, headers=travily_headers)\n",
        "    travily_items = travily_res.json().get(\"items\", [])\n",
        "    travily_context = \"\\n\".join([f\"{i+1}. {it.get('title', '제목없음')} ({it.get('url')})\" for i, it in enumerate(travily_items)]) or \"정보 없음\"\n",
        "\n",
        "    naver_url = \"https://openapi.naver.com/v1/search/news.json\"\n",
        "    naver_headers = {\"X-Naver-Client-Id\": naver_id, \"X-Naver-Client-Secret\": naver_secret}\n",
        "    naver_params = {\"query\": startup_name, \"display\": 5}\n",
        "    naver_res = requests.get(naver_url, params=naver_params, headers=naver_headers)\n",
        "    naver_items = naver_res.json().get(\"items\", [])\n",
        "    naver_context = \"\\n\".join([f\"{i+1}. {it.get('title', '제목없음')} – {it.get('description', '')} ({it.get('originallink')})\" for i, it in enumerate(naver_items)]) or \"정보 없음\"\n",
        "\n",
        "    response = (prompt | llm).invoke({\n",
        "        \"startup_name\": startup_name,\n",
        "        \"items\": items_formatted,\n",
        "        \"travily_context\": travily_context,\n",
        "        \"naver_context\": naver_context\n",
        "    })\n",
        "    analysis = response.content\n",
        "\n",
        "    # 점수 robust 파싱\n",
        "    score = extract_total_score_from_analysis(analysis)\n",
        "    if score is None:\n",
        "        score = extract_checklist_scores(analysis, checklist)\n",
        "\n",
        "    state[\"성장률_점수\"] = score\n",
        "    state[\"성장률_분석_근거\"] = analysis\n",
        "    return state\n",
        "\n",
        "# 점수 파싱 유틸 함수 (공통)\n",
        "def extract_total_score_from_analysis(analysis: str) -> int:\n",
        "    patterns = [\n",
        "        r\"\\*\\*총점\\*\\*[:：]?\\s*(\\d{1,3})\",\n",
        "        r\"총점[:：]?\\s*(\\d{1,3})\\s*(?:점|/100)?\",\n",
        "        r\"Score[:：]?\\s*(\\d{1,3})\\s*(?:점|/100)?\",\n",
        "    ]\n",
        "    for pattern in patterns:\n",
        "        match = re.search(pattern, analysis, re.IGNORECASE)\n",
        "        if match:\n",
        "            return int(match.group(1))\n",
        "    return None\n",
        "\n",
        "def extract_checklist_scores(analysis: str, checklist: List[str]) -> int:\n",
        "    clean_analysis = re.sub(r\"총점[:：]?\\s*\\d{1,3}\\s*(?:점|/100)?\", \"\", analysis, flags=re.IGNORECASE)\n",
        "    total_score = 0\n",
        "    for i, item in enumerate(checklist, 1):\n",
        "        patterns = [\n",
        "            fr\"{i}\\.\\s.*?(\\d{{1,2}})\\s*/\\s*10\",\n",
        "            fr\"{i}\\.\\s.*?(\\d{{1,2}})점\",\n",
        "            fr\"{i}\\.\\s.*?점수[:：]?\\s*(\\d{{1,2}})\",\n",
        "            fr\"{item}.*?(\\d{{1,2}})\\s*/\\s*10\",\n",
        "            fr\"{item}.*?(\\d{{1,2}})점\",\n",
        "            fr\"{item}.*?점수[:：]?\\s*(\\d{{1,2}})\",\n",
        "        ]\n",
        "        found = False\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, clean_analysis, re.DOTALL | re.IGNORECASE)\n",
        "            if match:\n",
        "                item_score = int(match.group(1))\n",
        "                total_score += item_score\n",
        "                found = True\n",
        "                break\n",
        "    return min(100, max(0, total_score))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def internal_judgement(state: AgentState) -> AgentState:\n",
        "    if (\n",
        "        state[\"상품_점수\"] < 40 or\n",
        "        state[\"기술_점수\"] < 40 or\n",
        "        state[\"성장률_점수\"] < 40\n",
        "    ):\n",
        "        state[\"최종_판단\"] = \"보류\"\n",
        "    elif (\n",
        "        (state[\"상품_점수\"] + state[\"기술_점수\"] + state[\"성장률_점수\"]) / 3 < 60\n",
        "    ):\n",
        "        state[\"최종_판단\"] = \"보류\"\n",
        "    return state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain_chroma'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[70], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_text_splitters\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RecursiveCharacterTextSplitter\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddings, ChatOpenAI\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_chroma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Chroma\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtavily_search\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TavilySearchResults\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain_chroma'"
          ]
        }
      ],
      "source": [
        "import os, re\n",
        "from typing import Dict, Any, List\n",
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "def analyze_market(state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    startup_name = state.get(\"startup_name\", \"\")\n",
        "    if not startup_name:\n",
        "        state[\"시장성_점수\"] = 0\n",
        "        state[\"시장성_분석_근거\"] = \"스타트업 이름이 제공되지 않았습니다.\"\n",
        "        return state\n",
        "\n",
        "    # ✅ PDF 폴더 내 전체 PDF 로드\n",
        "    pdf_dir = os.path.join(os.getcwd(), \"data\")\n",
        "    pdf_files = [f for f in os.listdir(pdf_dir) if f.lower().endswith(\".pdf\")]\n",
        "    print(f\"\\n[DEBUG] 폴더 내 PDF 파일 수: {len(pdf_files)}\")\n",
        "\n",
        "    all_docs = []\n",
        "    for pdf_file in pdf_files:\n",
        "        pdf_path = os.path.join(pdf_dir, pdf_file)\n",
        "        loader = PyMuPDFLoader(pdf_path)\n",
        "        split_docs = loader.load_and_split(RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100))\n",
        "        print(f\"[DEBUG] '{pdf_file}' → {len(split_docs)} 청크 생성\")\n",
        "        all_docs.extend(split_docs)\n",
        "\n",
        "    vector_store = Chroma.from_documents(all_docs, OpenAIEmbeddings())\n",
        "    retriever = vector_store.as_retriever()\n",
        "\n",
        "    retrieved_docs = retriever.get_relevant_documents(f\"{startup_name} 시장성, 시장 규모, 성장성, 수요 동향, 트렌드\")\n",
        "    print(f\"\\n[DEBUG] RAG 검색 결과 - 총 {len(retrieved_docs)}개\")\n",
        "    for i, doc in enumerate(retrieved_docs):\n",
        "        print(f\"\\n[RAG 결과 {i+1}] (Page: {doc.metadata.get('page', '알 수 없음')})\\n{doc.page_content[:300]}...\")\n",
        "\n",
        "    rag_context = \"\\n\\n\".join([f\"(Page: {doc.metadata.get('page', '알 수 없음')})\\n{doc.page_content}\" for doc in retrieved_docs]) or \"PDF에서 유의미한 정보 없음\"\n",
        "\n",
        "    # ✅ Web Search part (Tavily)\n",
        "    search_tool = TavilySearchResults(k=10)\n",
        "    web_results = search_tool.invoke(f\"{startup_name} AI 스타트업 시장성, 시장 규모, 성장성, 수요 동향, 트렌드 최근 6개월 기사\")\n",
        "    web_context = \"\\n\".join([f\"{i+1}. {result['title']} ({result['url']})\" for i, result in enumerate(web_results)]) or \"웹 검색에서 유의미한 정보 없음\"\n",
        "\n",
        "    combined_context = f\"[PDF 기반 RAG 검색 결과]\\n{rag_context}\\n\\n[웹 검색 결과]\\n{web_context}\"\n",
        "\n",
        "    print(f\"\\n[DEBUG] 최종 combined_context (앞 1000자):\\n{combined_context[:1000]}...\")\n",
        "\n",
        "    checklist = [\n",
        "        \"시장 규모 및 성장성\",\n",
        "        \"산업 내 수요 트렌드\",\n",
        "        \"고객군 다양성 및 확보 가능성\",\n",
        "        \"시장 진입 가능성 (규제, 장벽 등)\",\n",
        "        \"시장 내 대체재/경쟁 제품 존재 여부\",\n",
        "        \"향후 3~5년 성장 전망\",\n",
        "        \"국내외 시장 확장 가능성\",\n",
        "        \"산업 내 파트너쉽 및 생태계 가능성\",\n",
        "        \"사회적/경제적 메가트렌드 부합 여부\",\n",
        "        \"기술 변화에 따른 시장 위험성\"\n",
        "    ]\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        \"당신은 AI 스타트업 시장성 평가 전문가입니다. '{startup_name}'의 시장성을 종합적으로 평가해 주세요.\\n\\n\"\n",
        "        \"다음 정보를 종합하여 분석하세요:\\n{combined_context}\\n\\n\"\n",
        "        \"체크리스트:\\n\" +\n",
        "        \"\\n\".join([f\"{i+1}. {q}\" for i, q in enumerate(checklist)]) + \"\\n\\n\"\n",
        "        \"각 항목은 0점에서 10점 사이로 자유롭게 점수를 부여하세요.\\n\"\n",
        "        \"응답 형식:\\n\"\n",
        "        \"- 각 항목별 점수(0~10)와 **출처 포함한 분석 근거 (출처는 기사 제목, URL 또는 PDF 페이지 번호 명시)**\\n\"\n",
        "        \"- 결론 및 종합 분석\\n\"\n",
        "        \"- 총점: 점수 (숫자만 입력하세요, 예: 75)\"\n",
        "    )\n",
        "\n",
        "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "    chain = prompt | llm\n",
        "\n",
        "    response = chain.invoke({\n",
        "        \"startup_name\": startup_name,\n",
        "        \"combined_context\": combined_context,\n",
        "    })\n",
        "\n",
        "    analysis = response.content\n",
        "    print(f\"\\n[DEBUG] LLM 응답 (앞 1000자):\\n{analysis[:1000]}...\")\n",
        "\n",
        "    score = extract_total_score_from_analysis(analysis)\n",
        "    if score is None:\n",
        "        print(f\"\\n[DEBUG] 총점 파싱 실패 → 항목별 점수 직접 계산 시도\")\n",
        "        score = extract_checklist_scores(analysis, checklist)\n",
        "\n",
        "    print(f\"\\n[DEBUG] 최종 총점: {score}\")\n",
        "    state[\"시장성_점수\"] = score\n",
        "    state[\"시장성_분석_근거\"] = analysis\n",
        "    return state\n",
        "\n",
        "\n",
        "def extract_total_score_from_analysis(analysis: str) -> int:\n",
        "    patterns = [\n",
        "        r\"\\*\\*총점\\*\\*[:：]?\\s*(\\d{1,3})\",\n",
        "        r\"총점[:：]?\\s*(\\d{1,3})\\s*(?:점|/100)?\",\n",
        "        r\"Score[:：]?\\s*(\\d{1,3})\\s*(?:점|/100)?\",\n",
        "    ]\n",
        "    for pattern in patterns:\n",
        "        match = re.search(pattern, analysis, re.IGNORECASE)\n",
        "        if match:\n",
        "            print(f\"[DEBUG] 총점 파싱 성공: {match.group(1)}\")\n",
        "            return int(match.group(1))\n",
        "    return None\n",
        "\n",
        "def extract_checklist_scores(analysis: str, checklist: List[str]) -> int:\n",
        "    clean_analysis = re.sub(r\"총점[:：]?\\s*\\d{1,3}\\s*(?:점|/100)?\", \"\", analysis, flags=re.IGNORECASE)\n",
        "    total_score = 0\n",
        "    print(f\"\\n[DEBUG] 체크리스트별 점수 파싱 시작:\")\n",
        "    for i, item in enumerate(checklist, 1):\n",
        "        patterns = [\n",
        "            fr\"{i}\\.\\s.*?(\\d{{1,2}})\\s*/\\s*10\",\n",
        "            fr\"{i}\\.\\s.*?(\\d{{1,2}})점\",\n",
        "            fr\"{i}\\.\\s.*?점수[:：]?\\s*(\\d{{1,2}})\",\n",
        "            fr\"{item}.*?(\\d{{1,2}})\\s*/\\s*10\",\n",
        "            fr\"{item}.*?(\\d{{1,2}})점\",\n",
        "            fr\"{item}.*?점수[:：]?\\s*(\\d{{1,2}})\",\n",
        "        ]\n",
        "        found = False\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, clean_analysis, re.DOTALL | re.IGNORECASE)\n",
        "            if match:\n",
        "                item_score = int(match.group(1))\n",
        "                total_score += item_score\n",
        "                print(f\"- 항목 {i}: {item} → {item_score}점\")\n",
        "                found = True\n",
        "                break\n",
        "        if not found:\n",
        "            print(f\"- 항목 {i}: {item} → 점수 미발견 (0점 처리)\")\n",
        "    print(f\"[DEBUG] 체크리스트 총합: {total_score}\")\n",
        "    return min(100, max(0, total_score))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Dict, Any, List\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "import re\n",
        "\n",
        "def analyze_competitor(state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    startup_name = state.get(\"startup_name\", \"\")\n",
        "    if not startup_name:\n",
        "        state[\"경쟁사_점수\"] = 0\n",
        "        state[\"경쟁사_분석_근거\"] = \"스타트업 이름이 제공되지 않았습니다.\"\n",
        "        print(\"[DEBUG] 스타트업 이름 없음\")\n",
        "        return state\n",
        "\n",
        "    search_tool = TavilySearchResults(k=20)\n",
        "    search_results = search_tool.invoke(f\"{startup_name} 경쟁사 AI 스타트업 시장 분석 최근 6개월 기사\")\n",
        "\n",
        "    print(f\"\\n[DEBUG] 검색된 기사 수: {len(search_results)}개\")\n",
        "    for idx, result in enumerate(search_results, 1):\n",
        "        print(f\"{idx}. {result['title']}\")\n",
        "\n",
        "    if len(search_results) < 10:\n",
        "        print(\"[경고] 검색된 기사 수가 10개 미만입니다. 정보 부족으로 분석 신뢰도가 낮을 수 있습니다.\")\n",
        "\n",
        "    checklist = [\n",
        "        \"시장 진입 장벽 분석\",\n",
        "        \"주요 경쟁사 식별\",\n",
        "        \"경쟁사 제품/서비스 차별점\",\n",
        "        \"시장 점유율 데이터\",\n",
        "        \"가격 전략 비교\",\n",
        "        \"기술적 우위 분석\",\n",
        "        \"타겟 고객층 중복도\",\n",
        "        \"성장 속도 및 추세\",\n",
        "        \"투자 유치 상황\",\n",
        "        \"경쟁사 대응 전략 가능성\"\n",
        "    ]\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        \"당신은 AI 스타트업 경쟁 분석 전문가입니다. '{startup_name}'의 경쟁사 환경을 종합적으로 평가해 주세요.\\n\\n\"\n",
        "        \"최근 6개월 이내에 발행된 20개 이상의 기사를 기반으로, 다음 체크리스트의 각 항목을 평가하세요.\\n\"\n",
        "        \"각 항목은 0점에서 10점 사이로 자유롭게 점수를 부여할 수 있습니다. 점수 부여 기준:\\n\"\n",
        "        \"- 매우 우수하거나 충분히 충족 → 9~10점\\n\"\n",
        "        \"- 일부 충족되었거나 불완전 → 5~8점\\n\"\n",
        "        \"- 거의 정보가 없거나 충족되지 않음 → 0~4점\\n\\n\"\n",
        "        \"웹 검색 결과:\\n{search_results}\\n\\n\"\n",
        "        \"체크리스트:\\n\"\n",
        "        \"1. 시장 진입 장벽 분석\\n\"\n",
        "        \"2. 주요 경쟁사 식별\\n\"\n",
        "        \"3. 경쟁사 제품/서비스 차별점\\n\"\n",
        "        \"4. 시장 점유율 데이터\\n\"\n",
        "        \"5. 가격 전략 비교\\n\"\n",
        "        \"6. 기술적 우위 분석\\n\"\n",
        "        \"7. 타겟 고객층 중복도\\n\"\n",
        "        \"8. 성장 속도 및 추세\\n\"\n",
        "        \"9. 투자 유치 상황\\n\"\n",
        "        \"10. 경쟁사 대응 전략 가능성\\n\\n\"\n",
        "        \"응답 형식:\\n\"\n",
        "        \"- 각 항목별 점수(0~10)와 **출처 포함한 분석 근거 (출처는 기사 제목 또는 URL 명시)**\\n\"\n",
        "        \"- 결론 및 종합 분석\\n\"\n",
        "        \"- 총점: 점수 (숫자만 입력하세요, 예: 75)\"\n",
        "    )\n",
        "\n",
        "    chain = prompt | llm\n",
        "    response = chain.invoke({\n",
        "        \"startup_name\": startup_name,\n",
        "        \"search_results\": search_results\n",
        "    })\n",
        "\n",
        "    analysis = response.content\n",
        "    print(\"\\n[DEBUG] LLM 응답 내용:\")\n",
        "    print(analysis)\n",
        "\n",
        "    score = extract_total_score_from_analysis(analysis)\n",
        "    if score is None:\n",
        "        print(\"\\n[DEBUG] 총점 파싱 실패 → extract_checklist_scores_competitor()에서 항목별 점수 직접 계산\")\n",
        "        score = extract_checklist_scores_competitor(analysis, checklist)\n",
        "\n",
        "    state[\"경쟁사_점수\"] = score\n",
        "    state[\"경쟁사_분석_근거\"] = analysis\n",
        "    print(f\"[DEBUG] 최종 총점: {score}\")\n",
        "    return state\n",
        "\n",
        "\n",
        "def extract_total_score_from_analysis(analysis: str) -> int:\n",
        "    \"\"\"LLM 응답에서 다양한 총점 표현을 robust하게 파싱\"\"\"\n",
        "    patterns = [\n",
        "        r\"\\*\\*총점\\*\\*[:：]?\\s*(\\d{1,3})\",       # '**총점**: 69'\n",
        "        r\"총점[:：]?\\s*(\\d{1,3})\\s*(?:점|/100)?\",  # '총점: 69', '총점: 69점'\n",
        "        r\"Score[:：]?\\s*(\\d{1,3})\\s*(?:점|/100)?\",  # 'Score: 69', 'Score: 69/100'\n",
        "    ]\n",
        "    for pattern in patterns:\n",
        "        match = re.search(pattern, analysis, re.IGNORECASE)\n",
        "        if match:\n",
        "            print(f\"[DEBUG] 정규표현식으로 직접 파싱된 총점: {match.group(1)}\")\n",
        "            return int(match.group(1))\n",
        "    return None\n",
        "\n",
        "def extract_checklist_scores(analysis: str, checklist: List[str]) -> int:\n",
        "    \"\"\"체크리스트 항목별 점수를 유연하게 파싱 (다양한 표현 허용)\"\"\"\n",
        "    # ✅ 총점 제거\n",
        "    clean_analysis = re.sub(r\"총점[:：]?\\s*\\d{1,3}\\s*(?:점|/100)?\", \"\", analysis, flags=re.IGNORECASE)\n",
        "\n",
        "    total_score = 0\n",
        "    print(\"\\n[DEBUG] 체크리스트별 점수 파싱 시작:\")\n",
        "    for i, item in enumerate(checklist, 1):\n",
        "        # 모든 항목 공통적으로 사용할 패턴 리스트 (가장 일반적 → 구체적 순서로)\n",
        "        patterns = [\n",
        "            fr\"{i}\\.\\s.*?(\\d{{1,2}})\\s*/\\s*10\",  # '9/10'\n",
        "            fr\"{i}\\.\\s.*?(\\d{{1,2}})점\",         # '9점'\n",
        "            fr\"{i}\\.\\s.*?점수[:：]?\\s*(\\d{{1,2}})\",  # '점수: 9'\n",
        "            fr\"{item}.*?(\\d{{1,2}})\\s*/\\s*10\",\n",
        "            fr\"{item}.*?(\\d{{1,2}})점\",\n",
        "            fr\"{item}.*?점수[:：]?\\s*(\\d{{1,2}})\",\n",
        "        ]\n",
        "        found = False\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, clean_analysis, re.DOTALL | re.IGNORECASE)\n",
        "            if match:\n",
        "                item_score = int(match.group(1))\n",
        "                print(f\"- 항목 {i}: {item} → 점수: {item_score}\")\n",
        "                total_score += item_score\n",
        "                found = True\n",
        "                break\n",
        "        if not found:\n",
        "            print(f\"- 항목 {i}: {item} → 점수 찾지 못함 (0점 처리)\")\n",
        "\n",
        "    print(f\"[DEBUG] 체크리스트 총합 (정확한 합산): {total_score}\")\n",
        "    return min(100, max(0, total_score))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def final_judgement(state: AgentState) -> AgentState:\n",
        "    avg_internal = (state[\"상품_점수\"] + state[\"기술_점수\"] + state[\"성장률_점수\"]) / 3\n",
        "    avg_total = (avg_internal + state[\"시장성_점수\"] + state[\"경쟁사_점수\"]) / 3\n",
        "    state[\"최종_판단\"] = \"투자\" if avg_total >= 65 else \"보류\"\n",
        "    return state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_report(state: AgentState) -> AgentState:\n",
        "    startup_name = state.get(\"startup_name\", \"알 수 없는 스타트업\")\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        \"스타트업 '{startup_name}'에 대한 투자 심사 결과는 {최종_판단} 입니다. 점수 요약:\\n\"\n",
        "        \"- 상품/서비스: {상품_점수}\\n\"\n",
        "        \"- 기술: {기술_점수}\\n\"\n",
        "        \"- 성장률: {성장률_점수}\\n\"\n",
        "        \"- 시장성: {시장성_점수}\\n\"\n",
        "        \"- 경쟁사: {경쟁사_점수}\\n\\n\"\n",
        "        \"각 항목별 분석 근거:\\n\"\n",
        "        \"1. 상품/서비스 분석:\\n{상품_분석_근거}\\n\\n\"\n",
        "        \"2. 기술 분석:\\n{기술_분석_근거}\\n\\n\"\n",
        "        \"3. 성장률 분석:\\n{성장률_분석_근거}\\n\\n\"\n",
        "        \"4. 시장성 분석:\\n{시장성_분석_근거}\\n\\n\"\n",
        "        \"5. 경쟁사 분석:\\n{경쟁사_분석_근거}\\n\\n\"\n",
        "        \"위 분석 결과를 바탕으로 투자 심사 보고서를 작성하세요. 각 항목별 강점과 약점을 요약하고, \"\n",
        "        \"최종 판단의 근거를 명확히 제시하며, 개선이 필요한 부분에 대한 제안도 포함해주세요.\"\n",
        "    )\n",
        "    chain = prompt | llm\n",
        "    report = chain.invoke({\n",
        "        \"startup_name\": startup_name,\n",
        "        \"최종_판단\": state.get(\"최종_판단\", \"보류\"),\n",
        "        \"상품_점수\": state.get(\"상품_점수\", 0),\n",
        "        \"기술_점수\": state.get(\"기술_점수\", 0),\n",
        "        \"성장률_점수\": state.get(\"성장률_점수\", 0),\n",
        "        \"시장성_점수\": state.get(\"시장성_점수\", 0),\n",
        "        \"경쟁사_점수\": state.get(\"경쟁사_점수\", 0),\n",
        "        \"상품_분석_근거\": state.get(\"상품_분석_근거\", \"정보 없음\"),\n",
        "        \"기술_분석_근거\": state.get(\"기술_분석_근거\", \"정보 없음\"),\n",
        "        \"성장률_분석_근거\": state.get(\"성장률_분석_근거\", \"정보 없음\"),\n",
        "        \"시장성_분석_근거\": state.get(\"시장성_분석_근거\", \"정보 없음\"),\n",
        "        \"경쟁사_분석_근거\": state.get(\"경쟁사_분석_근거\", \"정보 없음\")\n",
        "    })\n",
        "    state[\"보고서\"] = report.content\n",
        "    return state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETX6gjn6PxW7",
        "outputId": "b2a51ad3-b9a5-4874-eeda-ccace750ce14"
      },
      "outputs": [],
      "source": [
        "import os, datetime, markdown2, pdfkit\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle\n",
        "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
        "from reportlab.lib import colors\n",
        "from reportlab.pdfbase import pdfmetrics\n",
        "from reportlab.pdfbase.ttfonts import TTFont\n",
        "\n",
        "# ─────────── 환경별 경로 수정 ───────────\n",
        "BASE_DIR = os.getcwd()\n",
        "\n",
        "WKHTMLTOPDF_BIN = os.path.join(BASE_DIR, \"wkhtmltopdf\", \"bin\", \"wkhtmltopdf.exe\")\n",
        "NANUM_REG_TTF   = os.path.join(BASE_DIR, \"font\", \"NanumGothic.ttf\")\n",
        "NANUM_BOLD_TTF  = os.path.join(BASE_DIR, \"font\", \"NanumGothicBold.ttf\")\n",
        "# ────────────────────────────────────────\n",
        "\n",
        "# 항상 들어갈 안내 문구\n",
        "NOTICE = \"상품/서비스, 기술, 성장률 중에 하나라도 40점 미만이면 시장성과 경쟁사 항목은 측정되지 않습니다.\"\n",
        "\n",
        "\n",
        "# 1) Markdown 생성\n",
        "def generate_markdown(state: dict, md_path: str) -> None:\n",
        "    sn  = state.get(\"startup_name\", \"알 수 없는 스타트업\")\n",
        "    rep = state.get(\"보고서\",       \"보고서 내용이 없습니다.\")\n",
        "    dec = state.get(\"최종_판단\",    \"보류\")\n",
        "\n",
        "    labels = [\"상품/서비스\",\"기술\",\"성장률\",\"시장성\",\"경쟁사\"]\n",
        "    keys   = [\"상품_점수\",\"기술_점수\",\"성장률_점수\",\"시장성_점수\",\"경쟁사_점수\"]\n",
        "    scores = [int(state.get(k,0)) for k in keys]\n",
        "    avg    = sum(scores)/len(scores)\n",
        "\n",
        "    dec_html = (\"<span style='color:green;'>투자</span>\"\n",
        "                if dec==\"투자\" else \"<span style='color:red;'>보류</span>\")\n",
        "\n",
        "    md = [\n",
        "        f\"<h1 align='center'>{sn} 투자 분석 보고서</h1>\", \"\",\n",
        "        f\"- **작성일** : {datetime.datetime.now():%Y년 %m월 %d일}\",\n",
        "        f\"- **최종 판단** : {dec_html}\", \"\", \"---\", \"\",\n",
        "        \"## 1. 점수 요약\", \"\",\n",
        "        \"| 평가 항목 | 점수 |\", \"|:-----------:|:----:|\",\n",
        "        *[f\"| {l} | **{v}** |\" for l,v in zip(labels,scores)],\n",
        "        f\"| **평균** | **{avg:.1f}** |\", \"\",\n",
        "        f\"> **{NOTICE}**\",                    # 안내문 삽입\n",
        "        \"\", \"---\", \"\",\n",
        "        \"## 2. 상세 분석\", \"\"\n",
        "    ]\n",
        "\n",
        "    # 상세 분석 – 줄바꿈 로직 그대로 유지\n",
        "    for line in rep.strip().splitlines():\n",
        "        if   line.startswith(\"### \"): md.append(f\"#### **{line[4:]}**\")\n",
        "        elif line.startswith(\"## \" ): md.append(f\"### **{line[3:]}**\")\n",
        "        elif line.startswith(\"# \"  ): md.append(f\"## **{line[2:]}**\")\n",
        "        else:                         md.append(line)\n",
        "\n",
        "    md += [\"\", \"---\", \"*이 보고서는 AI 분석 시스템에 의해 자동 생성되었습니다.*\"]\n",
        "\n",
        "    with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"\\n\".join(md))\n",
        "\n",
        "\n",
        "# 2) Markdown → PDF (wkhtmltopdf)\n",
        "def convert_md_to_pdf(md_path:str, pdf_path:str) -> None:\n",
        "    cfg = pdfkit.configuration(wkhtmltopdf=WKHTMLTOPDF_BIN)\n",
        "    with open(md_path,\"r\",encoding=\"utf-8\") as f:\n",
        "        body_html = markdown2.markdown(f.read(), extras=[\"tables\"])\n",
        "\n",
        "    if os.path.isfile(NANUM_REG_TTF):\n",
        "        reg  = os.path.abspath(NANUM_REG_TTF).replace(\"\\\\\",\"/\")\n",
        "        bold = os.path.abspath(NANUM_BOLD_TTF if os.path.isfile(NANUM_BOLD_TTF) else NANUM_REG_TTF).replace(\"\\\\\",\"/\")\n",
        "        font_css = (f\"@font-face{{font-family:'NanumGothic';src:url('file:///{reg}') format('truetype');font-weight:normal;}}\"\n",
        "                    f\"@font-face{{font-family:'NanumGothic';src:url('file:///{bold}') format('truetype');font-weight:bold;}}\")\n",
        "        family = \"NanumGothic\"\n",
        "    else:\n",
        "        font_css, family = \"\", \"sans-serif\"\n",
        "\n",
        "    style = f\"\"\"\n",
        "    <style>\n",
        "    {font_css}\n",
        "    body{{margin:40px 50px 60px;font-family:'{family}';line-height:1.6;font-size:11pt}}\n",
        "    h1{{font-size:20pt;text-align:center;margin-bottom:0.6em}}\n",
        "    h2{{font-size:15pt;margin-top:1.5em;margin-bottom:0.4em}}\n",
        "    table{{border-collapse:collapse;width:100%;margin-top:0.8em;font-size:10.5pt}}\n",
        "    th,td{{border:1px solid #666;padding:6px 8px;text-align:center}}\n",
        "    th{{background:#e0e0e0;font-weight:bold}}\n",
        "    tr:last-child td{{background:#f5f5f5;font-weight:bold}}\n",
        "    </style>\"\"\"\n",
        "\n",
        "    html = f\"<!DOCTYPE html><html><head><meta charset='utf-8'>{style}</head><body>{body_html}</body></html>\"\n",
        "    pdfkit.from_string(html, pdf_path, configuration=cfg,\n",
        "                       options={\"enable-local-file-access\":None,\"encoding\":\"utf-8\"})\n",
        "\n",
        "\n",
        "# 3) ReportLab PDF + MarkdownPDF 통합\n",
        "def generate_pdf(state: dict) -> dict:\n",
        "    sn     = state.get(\"startup_name\",\"알 수 없는 스타트업\")\n",
        "    today  = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
        "    out    = \"investment_reports\"; os.makedirs(out, exist_ok=True)\n",
        "    lab_pdf = os.path.join(out, f\"{sn}_투자분석보고서_{today}_lab.pdf\")\n",
        "    md_path = os.path.join(out, f\"{sn}_보고서.md\")\n",
        "    htmlpdf = os.path.join(out, f\"{sn}_투자분석보고서_{today}.pdf\")\n",
        "\n",
        "    doc, styles = SimpleDocTemplate(lab_pdf, pagesize=letter), getSampleStyleSheet()\n",
        "    try:\n",
        "        pdfmetrics.registerFont(TTFont(\"NanumGothic\",      NANUM_REG_TTF))\n",
        "        pdfmetrics.registerFont(TTFont(\"NanumGothic-Bold\", NANUM_BOLD_TTF))\n",
        "        base, bold = \"NanumGothic\", \"NanumGothic-Bold\"\n",
        "    except Exception:\n",
        "        base, bold = \"Helvetica\", \"Helvetica-Bold\"\n",
        "\n",
        "    styles.add(ParagraphStyle(\"ReportTitle\",   parent=styles[\"Heading1\"], fontSize=18, alignment=1, spaceAfter=20, fontName=base))\n",
        "    styles.add(ParagraphStyle(\"ReportSubtitle\",parent=styles[\"Heading2\"], fontSize=14, spaceBefore=10, spaceAfter=10, fontName=base))\n",
        "    styles.add(ParagraphStyle(\"SectionTitle\",  parent=styles[\"Normal\"],   fontSize=12, spaceBefore=8, spaceAfter=6, fontName=bold))\n",
        "    for n in [\"Normal\",\"Italic\",\"Heading1\",\"Heading2\",\"Heading3\",\"Heading4\",\"Heading5\",\"Heading6\"]:\n",
        "        styles[n].fontName = base\n",
        "\n",
        "    elems = [\n",
        "        Paragraph(f\"{sn} 투자 분석 보고서\", styles[\"ReportTitle\"]),\n",
        "        Paragraph(f\"작성일: {datetime.datetime.now():%Y년 %m월 %d일}\", styles[\"Normal\"]),\n",
        "        Spacer(1,20)\n",
        "    ]\n",
        "\n",
        "    color = \"green\" if state.get(\"최종_판단\")==\"투자\" else \"red\"\n",
        "    elems += [Paragraph(f\"최종 판단: <font color='{color}'><b>{state.get('최종_판단','보류')}</b></font>\",\n",
        "                        styles[\"ReportSubtitle\"]), Spacer(1,10)]\n",
        "\n",
        "    keys   = [\"상품_점수\",\"기술_점수\",\"성장률_점수\",\"시장성_점수\",\"경쟁사_점수\"]\n",
        "    labels = [\"상품/서비스\",\"기술\",\"성장률\",\"시장성\",\"경쟁사\"]\n",
        "    scores = [int(state.get(k,0)) for k in keys]\n",
        "    avg    = sum(scores)/len(scores)\n",
        "\n",
        "    t_data = [[\"평가 항목\",\"점수\"]] + [[l,str(s)] for l,s in zip(labels,scores)] + [[\"평균\",f\"{avg:.1f}\"]]\n",
        "    t = Table(t_data, colWidths=[300,100])\n",
        "    t.setStyle(TableStyle([\n",
        "        (\"BACKGROUND\",(0,0),(1,0),colors.grey), (\"TEXTCOLOR\",(0,0),(1,0),colors.whitesmoke),\n",
        "        (\"ALIGN\",(0,0),(1,0),\"CENTER\"), (\"FONTNAME\",(0,0),(1,0),bold),\n",
        "        (\"FONTNAME\",(0,1),(-1,-1),base), (\"GRID\",(0,0),(-1,-1),1,colors.black),\n",
        "        (\"BACKGROUND\",(0,-1),(1,-1),colors.lightgrey)\n",
        "    ]))\n",
        "    elems += [\n",
        "        Paragraph(\"점수 요약\", styles[\"ReportSubtitle\"]),\n",
        "        t, Spacer(1,12),\n",
        "        Paragraph(NOTICE, styles[\"Normal\"]),    # 안내문 삽입\n",
        "        Spacer(1,20)\n",
        "    ]\n",
        "\n",
        "    elems.append(Paragraph(\"상세 분석\", styles[\"ReportSubtitle\"]))\n",
        "    for ln in state.get(\"보고서\",\"\").splitlines():\n",
        "        if   ln.startswith(\"### \"): elems.append(Paragraph(ln[4:], styles[\"SectionTitle\"]))\n",
        "        elif ln.startswith(\"## \" ): elems.append(Paragraph(ln[3:], styles[\"SectionTitle\"]))\n",
        "        elif ln.startswith(\"# \"  ): elems.append(Paragraph(ln[2:], styles[\"SectionTitle\"]))\n",
        "        elif ln.strip():           elems.append(Paragraph(ln.strip(), styles[\"Normal\"]))\n",
        "        else:                      elems.append(Spacer(1,6))\n",
        "\n",
        "    elems += [Spacer(1,30),\n",
        "              Paragraph(\"이 보고서는 AI 분석 시스템에 의해 자동 생성되었습니다. \"\n",
        "                        f\"© {datetime.datetime.now().year}\", styles[\"Italic\"])]\n",
        "    doc.build(elems)\n",
        "\n",
        "    # Markdown + wkhtmltopdf\n",
        "    generate_markdown(state, md_path)\n",
        "    convert_md_to_pdf(md_path, htmlpdf)\n",
        "\n",
        "    state.update(pdf_path_reportlab = lab_pdf,\n",
        "                 pdf_path_wkhtml   = htmlpdf,\n",
        "                 markdown_path     = md_path,\n",
        "                 pdf_path          = htmlpdf)\n",
        "    return state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x207f1e90c70>"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 4. Graph 정의 및 연결\n",
        "graph = StateGraph(AgentState)\n",
        "\n",
        "graph.add_node(\"AnalyzeProduct\", analyze_product)\n",
        "graph.add_node(\"AnalyzeTechnology\", analyze_technology)\n",
        "graph.add_node(\"AnalyzeGrowth\", analyze_growth)\n",
        "graph.add_node(\"InternalJudgement\", internal_judgement)\n",
        "graph.add_node(\"AnalyzeMarket\", analyze_market)\n",
        "graph.add_node(\"AnalyzeCompetitor\", analyze_competitor)\n",
        "graph.add_node(\"FinalJudgement\", final_judgement)\n",
        "graph.add_node(\"GenerateReport\", generate_report)\n",
        "graph.add_node(\"GeneratePDF\", generate_pdf)  # PDF 생성 노드 추가\n",
        "\n",
        "graph.set_entry_point(\"AnalyzeProduct\")\n",
        "\n",
        "graph.add_edge(\"AnalyzeProduct\", \"AnalyzeTechnology\")\n",
        "graph.add_edge(\"AnalyzeTechnology\", \"AnalyzeGrowth\")\n",
        "graph.add_edge(\"AnalyzeGrowth\", \"InternalJudgement\")\n",
        "\n",
        "# 정의한 조건에 따라 다른 노드로 이동\n",
        "def route_after_internal_judgement(state: AgentState) -> str:\n",
        "    if state.get(\"최종_판단\") == \"보류\":\n",
        "        return \"GenerateReport\"\n",
        "    return \"AnalyzeMarket\"\n",
        "\n",
        "graph.add_conditional_edges(\n",
        "    \"InternalJudgement\",\n",
        "    route_after_internal_judgement\n",
        ")\n",
        "\n",
        "graph.add_edge(\"AnalyzeMarket\", \"AnalyzeCompetitor\")\n",
        "graph.add_edge(\"AnalyzeCompetitor\", \"FinalJudgement\")\n",
        "graph.add_edge(\"FinalJudgement\", \"GenerateReport\")\n",
        "graph.add_edge(\"GenerateReport\", \"GeneratePDF\")  # 보고서 생성 후 PDF 생성\n",
        "graph.add_edge(\"GeneratePDF\", END)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5OQFnU4SqqG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DEBUG] 정규표현식으로 직접 파싱된 총점: 82\n",
            "[DEBUG] 정규표현식으로 직접 파싱된 총점: 68\n",
            "[DEBUG] 정규표현식으로 직접 파싱된 총점: 61\n",
            "\n",
            "[DEBUG] 검색된 기사 수: 3개\n",
            "1. [주간투자동향] 비바리퍼블리카, 3,000억 원 규모의 투자 확보 - 다음뉴스\n",
            "2. 국내 AI 시장 6兆 돌파…성장 궤도 안착 - 전자신문\n",
            "3. 불황 때 열린 M&A 큰장…알짜 스타트업 사냥의 시간이 왔다 - 한국경제\n",
            "[경고] 검색된 기사 수가 10개 미만입니다. 정보 부족으로 분석 신뢰도가 낮을 수 있습니다.\n",
            "\n",
            "[DEBUG] LLM 응답 내용:\n",
            "비바리퍼블리카의 시장성을 평가하기 위해 주어진 체크리스트에 따라 각 항목을 분석하겠습니다.\n",
            "\n",
            "1. **시장 규모 및 성장성**: 8점\n",
            "   - 국내 AI 시장이 6조원을 돌파하며 안정적인 성장 궤도에 진입했다는 점에서 비바리퍼블리카가 속한 시장의 성장성이 높다고 평가할 수 있습니다. [출처: 전자신문]\n",
            "\n",
            "2. **산업 내 수요 트렌드**: 7점\n",
            "   - AI 응용 소프트웨어와 관련된 수요가 높으며, 이는 비바리퍼블리카의 서비스와 관련이 있을 가능성이 큽니다. [출처: 전자신문]\n",
            "\n",
            "3. **고객군 다양성 및 확보 가능성**: 6점\n",
            "   - B2B, B2G, B2C 등 다양한 고객군이 존재하지만, B2B 매출이 가장 많아 특정 고객군에 집중될 가능성이 있습니다. [출처: 전자신문]\n",
            "\n",
            "4. **시장 진입 가능성 (규제, 장벽 등)**: 5점\n",
            "   - AI 산업의 특성상 규제와 기술적 장벽이 존재할 수 있으며, 이는 시장 진입에 영향을 미칠 수 있습니다. [출처: 전자신문]\n",
            "\n",
            "5. **시장 내 대체재/경쟁 제품 존재 여부**: 6점\n",
            "   - AI 시장 내 다양한 응용 소프트웨어가 존재하므로 경쟁이 치열할 수 있습니다. [출처: 전자신문]\n",
            "\n",
            "6. **향후 3~5년 성장 전망**: 8점\n",
            "   - AI 시장의 지속적인 성장 전망이 긍정적이며, 이는 비바리퍼블리카의 성장에도 긍정적인 영향을 미칠 것입니다. [출처: 전자신문]\n",
            "\n",
            "7. **국내외 시장 확장 가능성**: 7점\n",
            "   - 국내 시장의 성장과 함께 해외 시장으로의 확장 가능성도 존재하지만, 구체적인 전략이 필요합니다. [출처: 전자신문]\n",
            "\n",
            "8. **산업 내 파트너쉽 및 생태계 가능성**: 7점\n",
            "   - AI 생태계 활성화를 위한 정책적 지원이 필요하다는 점에서 파트너쉽의 중요성이 강조됩니다. [출처: 전자신문]\n",
            "\n",
            "9. **사회적/경제적 메가트렌드 부합 여부**: 9점\n",
            "   - AI 기술은 현재 사회적, 경제적 메가트렌드에 부합하며, 이는 비바리퍼블리카의 시장성에 긍정적입니다. [출처: 전자신문]\n",
            "\n",
            "10. **기술 변화에 따른 시장 위험성**: 5점\n",
            "    - AI 기술의 빠른 변화는 시장 위험성을 증가시킬 수 있으며, 지속적인 기술 혁신이 필요합니다. [출처: 전자신문]\n",
            "\n",
            "**결론 및 종합 분석**:\n",
            "비바리퍼블리카는 AI 시장의 성장성과 메가트렌드에 부합하는 강점을 가지고 있으며, 다양한 고객군과 파트너쉽을 통해 시장 내 입지를 강화할 수 있는 잠재력이 있습니다. 그러나 기술 변화와 규제 등의 장벽을 극복하기 위한 전략이 필요합니다.\n",
            "\n",
            "**총점**: 68\n",
            "[DEBUG] 정규표현식으로 직접 파싱된 총점: 68\n",
            "[DEBUG] 최종 총점: 68\n",
            "\n",
            "[DEBUG] 검색된 기사 수: 5개\n",
            "1. 290억 모금한지 6개월 만에 '690억' 추가 유치…성장세 돋보이는 AI ...\n",
            "2. [주간투자동향] 비바리퍼블리카, 3,000억 원 규모의 투자 확보 - IT동아\n",
            "3. AI 스타트업 퍼플렉시티, 추가 투자로 기업가치 140억달러 인정\n",
            "4. AI 검색 스타트업 퍼플렉시티, 7000억원 펀딩 협상 막바지 - 전자신문\n",
            "5. AI 스타트업 '퍼플렉시티', 기업가치 140억 달러 인정 - 뉴시스\n",
            "[경고] 검색된 기사 수가 10개 미만입니다. 정보 부족으로 분석 신뢰도가 낮을 수 있습니다.\n",
            "\n",
            "[DEBUG] LLM 응답 내용:\n",
            "1. 시장 진입 장벽 분석: 6점\n",
            "   - **분석 근거**: 비바리퍼블리카와 같은 AI 스타트업은 기술 개발과 데이터 확보가 중요한 진입 장벽으로 작용합니다. 경쟁사인 퍼플렉시티가 구글과 같은 대형 기업과 경쟁하고 있는 점에서 진입 장벽이 높음을 알 수 있습니다. (출처: \"AI 검색 스타트업 퍼플렉시티, 7000억원 펀딩 협상 막바지 - 전자신문\")\n",
            "\n",
            "2. 주요 경쟁사 식별: 8점\n",
            "   - **분석 근거**: 주요 경쟁사로는 퍼플렉시티와 같은 AI 기반 검색 엔진 기업이 있으며, 이들은 구글과 오픈AI와도 경쟁하고 있습니다. (출처: \"AI 검색 스타트업 퍼플렉시티, 7000억원 펀딩 협상 막바지 - 전자신문\")\n",
            "\n",
            "3. 경쟁사 제품/서비스 차별점: 7점\n",
            "   - **분석 근거**: 퍼플렉시티는 AI를 이용해 웹에서 수집한 정보를 요약하여 제공하는 기능을 가지고 있으며, 이는 기존 검색 엔진과의 차별점입니다. (출처: \"AI 검색 스타트업 퍼플렉시티, 7000억원 펀딩 협상 막바지 - 전자신문\")\n",
            "\n",
            "4. 시장 점유율 데이터: 4점\n",
            "   - **분석 근거**: 구체적인 시장 점유율 데이터는 제공되지 않았으나, 퍼플렉시티가 구글의 지배력에 도전하고 있다는 점에서 시장 점유율 확보를 위한 노력이 진행 중임을 알 수 있습니다. (출처: \"AI 검색 스타트업 퍼플렉시티, 7000억원 펀딩 협상 막바지 - 전자신문\")\n",
            "\n",
            "5. 가격 전략 비교: 3점\n",
            "   - **분석 근거**: 가격 전략에 대한 구체적인 정보는 제공되지 않았습니다. AI 기반 서비스의 경우, 기술력과 서비스 품질이 가격 전략에 영향을 미칠 수 있습니다.\n",
            "\n",
            "6. 기술적 우위 분석: 7점\n",
            "   - **분석 근거**: 퍼플렉시티는 AI를 활용한 검색 엔진 기술을 보유하고 있으며, 이는 구글과 같은 대형 기업과 경쟁할 수 있는 기술적 우위를 나타냅니다. (출처: \"AI 검색 스타트업 퍼플렉시티, 7000억원 펀딩 협상 막바지 - 전자신문\")\n",
            "\n",
            "7. 타겟 고객층 중복도: 5점\n",
            "   - **분석 근거**: 비바리퍼블리카와 퍼플렉시티 모두 AI 기술을 활용한 서비스를 제공하지만, 구체적인 타겟 고객층에 대한 정보는 부족합니다.\n",
            "\n",
            "8. 성장 속도 및 추세: 9점\n",
            "   - **분석 근거**: 퍼플렉시티는 최근 기업 가치가 급격히 증가하고 있으며, 이는 AI 시장에서의 빠른 성장세를 나타냅니다. (출처: \"AI 스타트업 '퍼플렉시티', 기업가치 140억 달러 인정 - 뉴시스\")\n",
            "\n",
            "9. 투자 유치 상황: 10점\n",
            "   - **분석 근거**: 비바리퍼블리카는 3,000억 원 규모의 투자를 확보하였으며, 이는 강력한 투자 유치 상황을 나타냅니다. (출처: \"[주간투자동향] 비바리퍼블리카, 3,000억 원 규모의 투자 확보 - IT동아\")\n",
            "\n",
            "10. 경쟁사 대응 전략 가능성: 6점\n",
            "    - **분석 근거**: 퍼플렉시티와 같은 경쟁사는 구글과 오픈AI와의 경쟁을 통해 대응 전략을 마련하고 있으며, 이는 비바리퍼블리카에도 적용될 수 있는 전략적 가능성을 시사합니다. (출처: \"AI 검색 스타트업 퍼플렉시티, 7000억원 펀딩 협상 막바지 - 전자신문\")\n",
            "\n",
            "결론 및 종합 분석:\n",
            "비바리퍼블리카는 AI 시장에서 강력한 투자 유치와 기술적 우위를 바탕으로 성장하고 있습니다. 주요 경쟁사로는 퍼플렉시티와 같은 AI 기반 검색 엔진 기업이 있으며, 이들은 구글과 오픈AI와의 경쟁을 통해 시장 점유율을 확대하고 있습니다. 비바리퍼블리카는 이러한 경쟁 환경에서 기술적 차별화와 투자 유치를 통해 경쟁력을 강화할 필요가 있습니다.\n",
            "\n",
            "총점: 65\n",
            "[DEBUG] 정규표현식으로 직접 파싱된 총점: 65\n",
            "[DEBUG] 최종 총점: 65\n"
          ]
        },
        {
          "ename": "OSError",
          "evalue": "No wkhtmltopdf executable found: \"C:\\Users\\Administrator\\Desktop\\AI투자\\wkhtmltopdf\\bin\\wkhtmltopdf.exe\"\nIf this file exists please check that this process can read it or you can pass path to it manually in method call, check README. Otherwise please install wkhtmltopdf - https://github.com/JazzCore/python-pdfkit/wiki/Installing-wkhtmltopdf",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\lgw97\\Desktop\\skala_ai_startup_investment_evaluation_agent\\venv\\lib\\site-packages\\pdfkit\\configuration.py:35\u001b[0m, in \u001b[0;36mConfiguration.__init__\u001b[1;34m(self, wkhtmltopdf, meta_tag_prefix, environ)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwkhtmltopdf \u001b[38;5;241m=\u001b[39m lines[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwkhtmltopdf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Administrator\\\\Desktop\\\\AI투자\\\\wkhtmltopdf\\\\bin\\\\wkhtmltopdf.exe'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[31], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 초기 상태에 스타트업 이름 제공\u001b[39;00m\n\u001b[0;32m      5\u001b[0m initial_state \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstartup_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m비바리퍼플리카\u001b[39m\u001b[38;5;124m\"\u001b[39m}  \u001b[38;5;66;03m# 분석할 스타트업 이름 설정\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mcompiled_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# 6. 결과 확인\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m보고서 생성 완료: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpdf_path\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\lgw97\\Desktop\\skala_ai_startup_investment_evaluation_agent\\venv\\lib\\site-packages\\langgraph\\pregel\\__init__.py:2823\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[0m\n\u001b[0;32m   2820\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2821\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 2823\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m   2824\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   2825\u001b[0m     config,\n\u001b[0;32m   2826\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[0;32m   2827\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[0;32m   2828\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[0;32m   2829\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[0;32m   2830\u001b[0m     checkpoint_during\u001b[38;5;241m=\u001b[39mcheckpoint_during,\n\u001b[0;32m   2831\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[0;32m   2832\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2833\u001b[0m ):\n\u001b[0;32m   2834\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   2835\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2836\u001b[0m             \u001b[38;5;28misinstance\u001b[39m(chunk, \u001b[38;5;28mdict\u001b[39m)\n\u001b[0;32m   2837\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m (ints \u001b[38;5;241m:=\u001b[39m chunk\u001b[38;5;241m.\u001b[39mget(INTERRUPT)) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2838\u001b[0m         ):\n",
            "File \u001b[1;32mc:\\Users\\lgw97\\Desktop\\skala_ai_startup_investment_evaluation_agent\\venv\\lib\\site-packages\\langgraph\\pregel\\__init__.py:2461\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[0;32m   2455\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   2456\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[0;32m   2457\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   2458\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   2459\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[0;32m   2460\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[1;32m-> 2461\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   2462\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m   2463\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   2464\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[0;32m   2465\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   2466\u001b[0m         ):\n\u001b[0;32m   2467\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   2468\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[0;32m   2469\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\lgw97\\Desktop\\skala_ai_startup_investment_evaluation_agent\\venv\\lib\\site-packages\\langgraph\\pregel\\runner.py:153\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    151\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m                \u001b[49m\u001b[43mreraise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "File \u001b[1;32mc:\\Users\\lgw97\\Desktop\\skala_ai_startup_investment_evaluation_agent\\venv\\lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
            "File \u001b[1;32mc:\\Users\\lgw97\\Desktop\\skala_ai_startup_investment_evaluation_agent\\venv\\lib\\site-packages\\langgraph\\utils\\runnable.py:623\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m--> 623\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    625\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
            "File \u001b[1;32mc:\\Users\\lgw97\\Desktop\\skala_ai_startup_investment_evaluation_agent\\venv\\lib\\site-packages\\langgraph\\utils\\runnable.py:377\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    375\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 377\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
            "Cell \u001b[1;32mIn[29], line 153\u001b[0m, in \u001b[0;36mgenerate_pdf\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# ── Markdown & wkhtmltopdf PDF\u001b[39;00m\n\u001b[0;32m    152\u001b[0m generate_markdown(state, md_path)\n\u001b[1;32m--> 153\u001b[0m \u001b[43mconvert_md_to_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmd_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhtmlpdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m state\u001b[38;5;241m.\u001b[39mupdate(pdf_path_reportlab\u001b[38;5;241m=\u001b[39mlab_pdf,\n\u001b[0;32m    156\u001b[0m              pdf_path_wkhtml   \u001b[38;5;241m=\u001b[39mhtmlpdf,\n\u001b[0;32m    157\u001b[0m              markdown_path     \u001b[38;5;241m=\u001b[39mmd_path,\n\u001b[0;32m    158\u001b[0m              pdf_path          \u001b[38;5;241m=\u001b[39mhtmlpdf)     \u001b[38;5;66;03m# 대표 경로\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state\n",
            "Cell \u001b[1;32mIn[29], line 57\u001b[0m, in \u001b[0;36mconvert_md_to_pdf\u001b[1;34m(md_path, pdf_path)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconvert_md_to_pdf\u001b[39m(md_path:\u001b[38;5;28mstr\u001b[39m, pdf_path:\u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     cfg \u001b[38;5;241m=\u001b[39m \u001b[43mpdfkit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfiguration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwkhtmltopdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mWKHTMLTOPDF_BIN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(md_path,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m,encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     59\u001b[0m         body_html \u001b[38;5;241m=\u001b[39m markdown2\u001b[38;5;241m.\u001b[39mmarkdown(f\u001b[38;5;241m.\u001b[39mread(), extras\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtables\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
            "File \u001b[1;32mc:\\Users\\lgw97\\Desktop\\skala_ai_startup_investment_evaluation_agent\\venv\\lib\\site-packages\\pdfkit\\api.py:86\u001b[0m, in \u001b[0;36mconfiguration\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconfiguration\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     79\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;124;03m    Constructs and returns a :class:`Configuration` with given options\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03m    :param wkhtmltopdf: path to binary\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;124;03m    :param meta_tag_prefix: the prefix for ``pdfkit`` specific meta tags\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Configuration(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\lgw97\\Desktop\\skala_ai_startup_investment_evaluation_agent\\venv\\lib\\site-packages\\pdfkit\\configuration.py:38\u001b[0m, in \u001b[0;36mConfiguration.__init__\u001b[1;34m(self, wkhtmltopdf, meta_tag_prefix, environ)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIOError\u001b[39;00m, \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo wkhtmltopdf executable found: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     39\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf this file exists please check that this process can \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     40\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread it or you can pass path to it manually in method call, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     41\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheck README. Otherwise please install wkhtmltopdf - \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     42\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://github.com/JazzCore/python-pdfkit/wiki/Installing-wkhtmltopdf\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwkhtmltopdf)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menviron \u001b[38;5;241m=\u001b[39m environ\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menviron:\n",
            "\u001b[1;31mOSError\u001b[0m: No wkhtmltopdf executable found: \"C:\\Users\\Administrator\\Desktop\\AI투자\\wkhtmltopdf\\bin\\wkhtmltopdf.exe\"\nIf this file exists please check that this process can read it or you can pass path to it manually in method call, check README. Otherwise please install wkhtmltopdf - https://github.com/JazzCore/python-pdfkit/wiki/Installing-wkhtmltopdf"
          ]
        }
      ],
      "source": [
        "# 5. 실행\n",
        "compiled_graph = graph.compile()\n",
        "\n",
        "# 초기 상태에 스타트업 이름 제공\n",
        "initial_state = {\"startup_name\": \"비바리퍼플리카\"}  # 분석할 스타트업 이름 설정\n",
        "result = compiled_graph.invoke(initial_state)\n",
        "\n",
        "# 6. 결과 확인\n",
        "print(f\"보고서 생성 완료: {result['pdf_path']}\")\n",
        "print(\"\\n--- 보고서 내용 미리보기 ---\\n\")\n",
        "print(result[\"보고서\"][:500] + \"...\")  # 처음 500자만 출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"**투자 심사 보고서: 비바리퍼블리카**\\n\\n**1. 개요**\\n비바리퍼블리카는 모바일 금융서비스 '토스'를 통해 금융 서비스의 접근성을 높이고 사용자들이 보다 쉽게 금융 거래를 할 수 있도록 돕고 있는 스타트업입니다. 본 보고서는 비바리퍼블리카의 상품/서비스, 기술, 성장률, 시장성, 경쟁사 분석을 통해 투자 가능성을 평가합니다.\\n\\n**2. 항목별 분석**\\n\\n**2.1 상품/서비스 (총점: 82)**\\n- **강점**: 토스는 금융 서비스의 복잡성을 해결하며, 사용자 친화적인 인터페이스와 다양한 혁신적인 기능을 통해 높은 사용자 만족도를 얻고 있습니다. 또한, 명확한 문제 해결과 차별화된 기능을 통해 경쟁 제품 대비 우위를 점하고 있습니다.\\n- **약점**: 구체적인 가격 전략과 고객 피드백 수집 체계에 대한 정보가 부족합니다.\\n- **제안**: 가격 전략을 명확히 하고, 고객 피드백 수집 및 반영 체계를 강화하여 사용자 경험을 지속적으로 개선할 필요가 있습니다.\\n\\n**2.2 기술 (총점: 68)**\\n- **강점**: 비바리퍼블리카는 기술적 차별성을 가지고 있으며, 글로벌 스케일링 가능성이 높습니다. 다양한 금융 서비스를 성공적으로 구현하고 있어 기술 성숙도가 높습니다.\\n- **약점**: 특허 보유 여부, 기술 표준 준수 여부, 외부 인증 및 수상 이력에 대한 정보가 부족합니다.\\n- **제안**: 특허 및 외부 인증을 확보하여 기술적 신뢰성을 강화하고, 기술 표준 준수 여부를 명확히 할 필요가 있습니다.\\n\\n**2.3 성장률 (총점: 61)**\\n- **강점**: 토스인슈어런스의 매출이 급격히 증가하고 있으며, 해외 시장 진출에 적극적인 계획을 가지고 있습니다.\\n- **약점**: 고객 유지율, 활성 사용자 증가, 신규 계약 증가, 연간 반복 매출 성장에 대한 구체적인 데이터가 부족합니다.\\n- **제안**: 고객 유지율과 활성 사용자 증가를 위한 전략을 강화하고, 신규 계약 및 연간 반복 매출 성장에 대한 구체적인 목표를 설정할 필요가 있습니다.\\n\\n**2.4 시장성 (총점: 67)**\\n- **강점**: AI 시장의 성장성과 메가트렌드에 부합하며, 국내외 시장 확장 가능성이 높습니다.\\n- **약점**: 규제와 기술적 장벽, 경쟁의 치열함, 기술 변화에 따른 시장 위험성이 존재합니다.\\n- **제안**: 규제 대응 전략을 마련하고, 기술적 장벽을 극복하기 위한 연구개발을 강화하며, 경쟁사와의 차별화를 위한 전략을 수립할 필요가 있습니다.\\n\\n**2.5 경쟁사 (총점: 63)**\\n- **강점**: 비바리퍼블리카는 3,000억 원 규모의 투자를 확보하며 성장 가능성을 보여주고 있습니다.\\n- **약점**: 시장 점유율 데이터와 가격 전략에 대한 정보가 부족하며, 경쟁사들이 빠르게 성장하고 있습니다.\\n- **제안**: 시장 점유율을 확대하기 위한 전략을 수립하고, 경쟁사와의 차별화를 위한 기술 개발 및 마케팅 전략을 강화할 필요가 있습니다.\\n\\n**3. 최종 판단 및 제안**\\n비바리퍼블리카는 금융 서비스의 혁신을 통해 높은 성장 가능성을 보유하고 있으며, 글로벌 시장 진출을 위한 구체적인 계획을 가지고 있습니다. 그러나 기술적 신뢰성 강화, 고객 유지율 개선, 규제 대응 전략 마련 등 몇 가지 개선이 필요한 부분이 있습니다. 이러한 부분을 보완한다면, 비바리퍼블리카는 더욱 강력한 경쟁력을 갖출 수 있을 것입니다. 따라서, 비바리퍼블리카에 대한 투자는 긍정적으로 평가되며, 지속적인 모니터링과 지원이 필요합니다.\""
            ]
          },
          "execution_count": 764,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result[\"보고서\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
